{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook evaluates the results form the user study. Set `FILL_DATABASE` to True to create a mock database. Set it to False to use the results from an existing database.\n",
    "\n",
    "If mocking data, this notebook expects the server to run on `server_url` with a database with no entries, as set up by running `node setup.mjs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_STUDY_CSV = \"./results/user_study/selection.csv\"\n",
    "SQLITE_DB = \"../survey/db_final.db\"\n",
    "FILL_DATABASE = False # if True, data is mocked, THIS CALLS THE APIs\n",
    "\n",
    "server_url = \"http://localhost:3002\" # server to mock data on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import krippendorff\n",
    "from scipy.stats import ttest_rel\n",
    "from scipy.stats import ttest_1samp\n",
    "import numpy as np \n",
    "import scipy.stats as stats \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "connection = sqlite3.connect(SQLITE_DB)\n",
    "\n",
    "user_df = pd.read_sql_query(\"SELECT * FROM users\", connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_study = pd.read_csv(USER_STUDY_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Database\n",
    "If `FILL_DATABASE` is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile run_user.py\n",
    "\n",
    "def run_user(idx, user, url, df_user_study):\n",
    "    n_learn = 16\n",
    "    n_eval = 16\n",
    "    n_users = 10\n",
    "\n",
    "    mu_got_it_right_pre=0.5\n",
    "    sigma_got_it_right_pre=0.05\n",
    "    mu_gain = 0.2\n",
    "    sigma_gain = 0.1\n",
    "\n",
    "    def guess(detector_label,p):\n",
    "        return detector_label if bool(np.random.choice([0,1],p=[1-p, p])) else not detector_label\n",
    "\n",
    "    import requests\n",
    "    import json\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    user_dist_without = lambda : np.clip(np.random.normal(mu_got_it_right_pre, sigma_got_it_right_pre, 1)[0], 0,1)\n",
    "    user_dist_gain = lambda : np.clip(np.random.normal(mu_gain, sigma_gain, 1)[0], -1,1)\n",
    "  \n",
    "    res = requests.get(url+\"/auth/\"+ user[\"access_token\"])\n",
    "\n",
    "    print(res.text)\n",
    "    auth_token = json.loads(res.text)\n",
    "    headers = {'Content-Type': 'application/json','Authorization': \"Bearer \"+auth_token, \"Content-Type\": \"application/json\",}\n",
    "\n",
    "    requests.post(url+\"/api/submitParticipantInfo\", json={\n",
    "    \"has_seen_explanation_methods_before\": \"yes\",\n",
    "    \"has_seen_OTHERS_before\": \"yes\",\n",
    "    \"level_of_expertise\": \"is-researcher-explainability\",\n",
    "    \"familiarity_with_chatgpt\": \"occasional-use\",\n",
    "    \"prefers_monochromatic_methods\": \"yes\" if idx % 20 == 0 else \"no\"\n",
    "    }, headers=headers)\n",
    "    # go to phase 2\n",
    "    requests.post(url+\"/api/completeCurrentPhase\", json={\"expected\": 0}, headers=headers)\n",
    "    # if idx % 8 == 0:\n",
    "    #     return\n",
    "    requests.post(url+\"/api/completeCurrentPhase\", json={\"expected\": 1}, headers=headers)\n",
    "    requests.post(url+\"/api/completeCurrentPhase\", json={\"expected\": 2}, headers=headers)\n",
    "\n",
    "    res = requests.get(url+\"/api/state\", headers=headers)\n",
    "    state = json.loads(res.text)\n",
    "\n",
    "    # user_df = pd.read_sql_query(\"SELECT * FROM users\", connection) # update as group is assigned now\n",
    "    # user = user_df.iloc[idx]\n",
    "   # print(user[[\"detector\", \"explainer\"]])\n",
    "    # return state\n",
    "    df_user_documents = df_user_study.loc[df_user_study.groupby(\"Detector\").groups[state[\"detector\"]],:].reset_index(drop=True)\n",
    "    for doc_nr, row in df_user_documents.iterrows():\n",
    "        p_without = user_dist_without()\n",
    "        requests.post(url+\"/api/submitPhase2\", json={\"ID\": doc_nr, \"label\": guess(row[\"f(b)\"], p_without)}, headers=headers)\n",
    "    requests.post(url+\"/api/completeCurrentPhase\", json={\"expected\": 3}, headers=headers)\n",
    "\n",
    "    for doc_nr, row in df_user_documents.iterrows():\n",
    "        json_ = {\"lickert-q{}-{}\".format(question_nr, doc_nr): str(np.random.choice([1,2,3,4,5], p=[0.1,0.2,0.1,0.4,0.2])) for question_nr in range(1,4)}\n",
    "        json_[\"document_nr\"] = doc_nr\n",
    "        requests.post(url+\"/api/submitPhase3\", json=json_, headers=headers)\n",
    "\n",
    "    requests.post(url+\"/api/completeCurrentPhase\", json={\"expected\": 4}, headers=headers)\n",
    "    for doc_nr, row in df_user_documents.iterrows():\n",
    "        p_with = np.clip(p_without + user_dist_gain(), 0,1)\n",
    "        requests.post(url+\"/api/submitPhase4\", json={\"ID\": doc_nr, \"label\": guess(row[\"f(b)\"], p_with)}, headers=headers)\n",
    "    requests.post(url+\"/api/completeCurrentPhase\", json={\"expected\": 5}, headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from multiprocess import Pool\n",
    "from run_user import run_user\n",
    "\n",
    "\n",
    "if FILL_DATABASE:\n",
    "    max_pool = 10\n",
    "    mock_user_data = [(idx, user, server_url, df_user_study) for idx, user in user_df.iterrows() if idx < 27]\n",
    "\n",
    "    with Pool(max_pool) as p:\n",
    "        pool_outputs = list(tqdm(p.starmap(run_user,mock_user_data),total=len(mock_user_data)))    \n",
    "    print(pool_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "### Participant Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_info = pd.read_sql_query(\"SELECT participant_info.*, users.detector, users.explainer FROM participant_info INNER JOIN users ON participant_info.user_id = users.ID where users.current_phase = 5\", connection)\n",
    "participant_info.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = lambda col_name : display(participant_info[col_name].value_counts(normalize=True).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat(\"has_seen_explanation_methods_before\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat(\"level_of_expertise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat(\"familiarity_with_chatgpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat(\"has_seen_explanation_methods_before\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two more users for Guo+SHAP and Radford+Anchor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_sql_query(\"SELECT * FROM users where current_phase = 5\", connection) # remove the two last \n",
    "user_df.groupby([\"detector\", \"explainer\"])[\"ID\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclude the last two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_sql_query(\"SELECT * FROM users where current_phase = 5 and users.id != 76 and users.id != 45\", connection) # remove the two last "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.groupby([\"detector\", \"explainer\"])[\"ID\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_is_correct(df_user_responses, df_user_study):\n",
    "    \"\"\"Returns a dataframe that specifies wheter the users correctly guessed the detector's decision for each document\n",
    "\n",
    "    Args:\n",
    "        df_user_responses: Responses from user study\n",
    "        df_user_study: Documents for user study\n",
    "    \"\"\"\n",
    "    detector = df_user_responses.iloc[0][\"detector\"] \n",
    "\n",
    "    df_user_documents = df_user_study.loc[df_user_study.groupby(\"Detector\").groups[detector],:].reset_index(drop=True) # decisions differ by detector\n",
    "    detector_predictions = df_user_documents[\"f(b)\"].astype(bool) # set B\n",
    "    user_responses = df_user_responses.loc[df_user_responses.groupby(\"document_nr\")[\"timestamp\"].idxmax()].set_index(\"document_nr\")[\"label\"].astype(bool) # only keep most recent response\n",
    "\n",
    "    return user_responses == detector_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = user_df.set_index(\"ID\").rename_axis(\"user_id\")[[\"explainer\", \"detector\"]] # rename for join\n",
    "\n",
    "# get from DB\n",
    "df_phase_2 = pd.read_sql_query(\"SELECT responses_phase_2.*, users.detector, users.explainer FROM responses_phase_2 INNER JOIN users ON responses_phase_2.user_id = users.ID\", connection)\n",
    "df_phase_4 = pd.read_sql_query(\"SELECT responses_phase_4.*, users.detector, users.explainer FROM responses_phase_4 INNER JOIN users ON responses_phase_4.user_id = users.ID\", connection)\n",
    "\n",
    "# get two dataframes \"is_correct_phase_2\"\n",
    "is_correct_phase_4 = df_phase_4.groupby([\"user_id\"]).apply(lambda df_user_responses : get_is_correct(df_user_responses,df_user_study))\n",
    "is_correct_phase_2 = df_phase_2.groupby([\"user_id\"]).apply(lambda df_user_responses : get_is_correct(df_user_responses,df_user_study))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar, SquareTable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method level\n",
    "\n",
    "results = []\n",
    "for explainer, _ in u.groupby(\"explainer\"):\n",
    "    # get contingency table by explainer\n",
    "    phase_2 = u.join(is_correct_phase_2).loc[(u.join(is_correct_phase_2)[\"explainer\"] == explainer)].set_index([\"explainer\", \"detector\"])\n",
    "    phase_4 = u.join(is_correct_phase_4).loc[(u.join(is_correct_phase_4)[\"explainer\"] == explainer)].set_index([\"explainer\", \"detector\"])\n",
    "\n",
    "    contingency_table =SquareTable.from_data(pd.concat([phase_2.melt()[\"value\"], phase_4.melt()[\"value\"]], axis=1))\n",
    " \n",
    "    marginal_row_prob, marginal_col_prob = contingency_table.marginal_probabilities\n",
    " \n",
    "    user_accuracy_4 = marginal_col_prob[True]\n",
    "    user_accuracy_2 = marginal_row_prob[True]\n",
    "\n",
    "    m = mcnemar(contingency_table.table,exact=True) # use binominal distribution, p value already multiplied by 2\n",
    "\n",
    "    results.append((explainer.replace(\"_Explainer\", \"\"),  #matrix, marginal_frequencies, \n",
    "                    user_accuracy_2,\n",
    "                    user_accuracy_4,\n",
    "                    ((user_accuracy_4 / user_accuracy_2) -1.0),\n",
    "                    m.pvalue#, m.statistic\n",
    "                    ))\n",
    "df = pd.DataFrame(results, columns=[\n",
    "    \"\", \n",
    "    \"User Acc without\",\n",
    "    \"User Acc with\",\n",
    "    \"Change\", \n",
    "    \"p\"]).sort_values(by=[\"Change\"], ascending=False).style.format({\n",
    "    \"User Acc without\": \"{:.3f}\".format,\n",
    "    \"User Acc with\": \"{:.3f}\".format,\n",
    "    \"Change\": \"{:.2%}\".format,\n",
    "    \"p\": \"{:.3f}\".format,\n",
    "}).hide(axis=\"index\")\n",
    "latex_output.append(df.to_latex(environment=\"table\", \n",
    "                                    convert_css=True, \n",
    "                                    clines=\"all;data\", \n",
    "                                    hrules=True, \n",
    "                \n",
    "                                    caption=\"Forward simulation experiment by method\", \n",
    "                                    label=\"user-study-per-method\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group level, (redundant but with different groupby)\n",
    "\n",
    "results = []\n",
    "for (explainer, detector),_ in u.groupby([\"explainer\",\"detector\"]):\n",
    "    # get contingency table by explainer\n",
    "    phase_2 = u.join(is_correct_phase_2).loc[(u.join(is_correct_phase_2)[\"explainer\"] == explainer) & (u.join(is_correct_phase_2)[\"detector\"] == detector)].set_index([\"explainer\", \"detector\"])\n",
    "    phase_4 = u.join(is_correct_phase_4).loc[(u.join(is_correct_phase_4)[\"explainer\"] == explainer) & (u.join(is_correct_phase_2)[\"detector\"] == detector)].set_index([\"explainer\", \"detector\"])\n",
    "\n",
    "    contingency_table =SquareTable.from_data(pd.concat([phase_2.melt()[\"value\"], phase_4.melt()[\"value\"]], axis=1))\n",
    " \n",
    "    marginal_row_prob, marginal_col_prob = contingency_table.marginal_probabilities\n",
    " \n",
    "    user_accuracy_4 = marginal_col_prob[True]\n",
    "    user_accuracy_2 = marginal_row_prob[True]\n",
    "\n",
    "    m = mcnemar(contingency_table.table,exact=True) # use binominal distribution, p value already multiplied by 2\n",
    "\n",
    "    results.append((explainer.replace(\"_Explainer\", \"\"), detector.replace(\"Detector\", \"\"), #matrix, marginal_frequencies, \n",
    "                    user_accuracy_2,\n",
    "                    user_accuracy_4,\n",
    "                    ((user_accuracy_4 / user_accuracy_2) -1.0),\n",
    "                    m.pvalue#, m.statistic\n",
    "                    ))\n",
    "df = pd.DataFrame(results, columns=[\n",
    "    \"\",\n",
    "    \"\", \n",
    "    \"User Acc without\",\n",
    "    \"User Acc with\",\n",
    "    \"Change\", \n",
    "    \"p\"]).sort_values(by=[\"Change\"], ascending=False).style.format({\n",
    "    \"User Acc without\": \"{:.3f}\".format,\n",
    "    \"User Acc with\": \"{:.3f}\".format,\n",
    "    \"Change\": \"{:.2%}\".format,\n",
    "    \"p\": \"{:.3f}\".format,\n",
    "}).hide(axis=\"index\")\n",
    "latex_output.append(df.to_latex(environment=\"table\", \n",
    "                                    convert_css=True, \n",
    "                                    clines=\"all;data\", \n",
    "                \n",
    "                                    hrules=True, \n",
    "                                    caption=\"Forward simulation experiment by group\", \n",
    "                                    label=\"user-study-per-group\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phase_3 = pd.read_sql_query(\"SELECT responses_phase_3.*, users.detector, users.explainer FROM responses_phase_3 INNER JOIN users ON responses_phase_3.user_id = users.ID where users.current_phase = 5 and users.id != 76 and users.id != 45\", connection)\n",
    "# remove the two additional participants (see above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep most recent responses\n",
    "user_responses = df_phase_3.loc[df_phase_3.groupby([\"user_id\", \"question_nr\", \"document_nr\"])[\"timestamp\"].idxmax()].set_index([\"user_id\", \"document_nr\", \"question_nr\"]).drop([\"timestamp\", \"ID\"], axis=1)\n",
    "user_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(user_responses) == 36*18*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_responses.reset_index().set_index([\"detector\", \"user_id\", \"document_nr\"]).groupby([\"explainer\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_significant(row, props=''):\n",
    "  #  display(s)\n",
    "    styles = [''] * len(row)\n",
    "    styles[0] = 'font-weight: bold' if row[\"p value\"] <= 0.05 else ''\n",
    "    return styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregate_results_lickert(groupby, label, caption):\n",
    "    df_aggregate_results = pd.DataFrame(user_responses.groupby(groupby)[\"label\"].mean())\n",
    "    \n",
    "    #df_aggregate_results = df_aggregate_results.reindex(sorted(df_aggregate_results.columns), axis=1)\n",
    "    df_aggregate_results = df_aggregate_results.reset_index()\n",
    "    df_aggregate_results[\"explainer\"] = df_aggregate_results[\"explainer\"].str.replace(\"_Explainer\", \"\")\n",
    "    if \"detector\" in groupby:\n",
    "        df_aggregate_results[\"detector\"] = df_aggregate_results[\"detector\"].str.replace(\"Detector\", \"\")\n",
    "    df_aggregate_results = df_aggregate_results.rename({\"question_nr\":\"Question\"}, axis=1)\n",
    "    df_aggregate_results = df_aggregate_results.set_index(groupby[0:-1]+[\"Question\"])\n",
    "    df_aggregate_results.plot.bar()\n",
    "    \n",
    "    result = df_aggregate_results.style.format(precision=2).format_index(escape=\"latex\", axis=0)\n",
    "    latex_output.append(result.to_latex(environment=\"table\", \n",
    "                                        convert_css=True, \n",
    "                                        clines=\"all;data\", \n",
    "                                        hrules=True, \n",
    "                                        caption=caption, \n",
    "                                        label=label))\n",
    "\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_aggregate_results_lickert([\"detector\", \"explainer\", \"question_nr\"], \"rating-group\",\"Rating task at the group level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_aggregate_results_lickert([ \"explainer\", \"question_nr\"], \"lickert-explainer\",\"Rating task on the method level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"figures/tables_user_study.tex\", \"w\", encoding=\"UTF-8\") as text_file:\n",
    "    text_file.write(\"\\n\".join(latex_output).replace(\"%\", u\"\"\"\\%\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
