{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook evaluates the results form the user study. Set `FILL_DATABASE` to True to create a mock database. Set it to False to use the results from an existing database.\n",
    "\n",
    "If mocking data, this notebook expects the server to run on `server_url` with a database with no entries, as set up by running `node setup.mjs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_STUDY_CSV = \"./dataset_user_study.csv\"\n",
    "SQLITE_DB = \"../survey/db.db\"\n",
    "FILL_DATABASE = True # if True, data is mocked, THIS CALLS THE APIs\n",
    "\n",
    "server_url = \"http://localhost:3002\" # server to mock data on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import krippendorff\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import ttest_1samp\n",
    "import numpy as np \n",
    "import scipy.stats as stats \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from Hase et al. 2020. Main points:\n",
    "\n",
    "This is a within-subject* design with 4 phases: (1) Predictions only, (2) Pre-learn test, (3) Teaching: Predictions + Explanations, (4) Eval.\n",
    "\n",
    "Phase 1 and 3 share a set of documents as do 2 and 4.\n",
    "\n",
    "Result Hase et al.: Report **average change** in user accuracy per explanation method (phase 2 vs. 4), CI and p values of mean\n",
    "\n",
    "Additional details by Hase et al.:\n",
    "- Balance data \"by model correctness\" so random guessing can't succeed: *\"we ensure that true positives, false positives,\n",
    "true negatives, and false negatives are equally represented in the inputs. [...] We confirm user understanding of the data\n",
    "balancing in our screening test\"*\n",
    "- Forced choice, to not \"favor overly niche explanations\" (like in Ribeiro et al.)\n",
    "- Separate teach and test phases\n",
    "- Pre prediction phase to obtain a baseline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "connection = sqlite3.connect(SQLITE_DB)\n",
    "\n",
    "user_df = pd.read_sql_query(\"SELECT * FROM users\", connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>access_token</th>\n",
       "      <th>current_phase</th>\n",
       "      <th>detector</th>\n",
       "      <th>explainer</th>\n",
       "      <th>document_order_a</th>\n",
       "      <th>document_order_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>YOEMSM</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[12,11,1,6,16,15,2,9,13,8,0,4,14,7,17,5,3,10]</td>\n",
       "      <td>[15,14,0,10,9,7,13,8,3,5,16,2,4,12,1,6,17,11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>LDJVYN</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[11,4,15,1,10,14,2,13,5,8,7,16,6,0,9,3,17,12]</td>\n",
       "      <td>[2,10,6,1,5,4,15,12,16,8,3,17,9,11,7,14,0,13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>DDYXJD</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[6,4,8,9,5,14,0,13,15,12,10,16,7,1,3,2,17,11]</td>\n",
       "      <td>[10,15,17,1,0,11,9,2,13,7,16,14,3,4,5,12,6,8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>KHGHUI</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[8,16,6,4,9,7,17,1,12,0,2,13,11,15,10,5,3,14]</td>\n",
       "      <td>[9,15,6,3,13,14,16,12,2,17,4,1,7,8,10,0,5,11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>LIQXER</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[2,1,13,8,6,12,15,14,7,4,0,17,3,11,9,10,16,5]</td>\n",
       "      <td>[12,14,15,4,6,13,3,8,2,11,16,9,1,0,5,10,7,17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>ZLWEGL</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[10,2,1,3,0,5,15,17,16,13,11,9,14,4,12,6,7,8]</td>\n",
       "      <td>[14,17,6,1,8,12,5,13,11,3,9,7,16,4,0,10,2,15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>YOBXBC</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[12,3,17,14,11,2,9,7,8,4,1,16,6,5,15,10,0,13]</td>\n",
       "      <td>[8,15,3,13,4,10,6,17,5,0,12,11,1,9,14,7,2,16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>LKKCKR</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[5,15,3,11,1,0,6,2,10,12,16,17,14,4,13,9,8,7]</td>\n",
       "      <td>[2,9,16,15,1,6,3,17,7,11,0,13,4,8,10,5,12,14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>FXPIKS</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[5,8,9,0,15,2,14,17,16,1,4,12,7,11,3,6,13,10]</td>\n",
       "      <td>[0,4,2,7,6,3,13,10,1,5,8,15,12,11,9,17,16,14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>WYBNGV</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[3,5,17,10,13,2,6,1,16,14,15,12,4,11,0,8,9,7]</td>\n",
       "      <td>[14,2,15,13,1,12,17,4,0,9,3,7,6,8,11,10,16,5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>UBEKJT</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[12,2,9,7,6,17,4,10,14,8,13,1,3,15,0,11,16,5]</td>\n",
       "      <td>[7,2,9,16,12,5,6,3,11,4,13,10,8,14,15,1,17,0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>AQVGKB</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[14,0,3,5,15,8,9,11,7,4,17,13,6,10,1,12,16,2]</td>\n",
       "      <td>[6,4,17,8,3,15,2,5,13,12,16,1,9,14,0,11,7,10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>JRHLOX</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[15,6,17,7,3,13,9,16,12,14,1,10,2,11,8,0,4,5]</td>\n",
       "      <td>[9,3,8,2,5,15,7,6,0,11,14,12,17,10,13,1,16,4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>UJLPKI</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[8,14,13,0,6,2,9,1,16,5,3,10,17,12,15,4,11,7]</td>\n",
       "      <td>[7,6,11,12,5,4,8,16,14,13,3,2,9,1,0,17,10,15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>CAPYDK</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[2,17,3,11,14,4,1,8,5,15,13,0,10,16,9,7,6,12]</td>\n",
       "      <td>[0,1,13,7,14,6,2,3,12,8,4,10,17,15,5,9,16,11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>PLZDRA</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[7,17,1,9,6,0,11,12,15,4,14,3,8,5,10,16,2,13]</td>\n",
       "      <td>[16,2,7,15,1,11,5,0,3,10,4,12,14,13,9,8,6,17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>OZJPSK</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[6,4,3,2,16,11,17,8,12,7,1,9,10,13,15,14,5,0]</td>\n",
       "      <td>[2,10,15,5,11,17,6,16,9,1,3,0,7,13,4,14,12,8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>XNVNLA</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[13,14,6,15,7,10,17,0,9,1,16,2,3,12,11,4,8,5]</td>\n",
       "      <td>[7,0,10,1,9,12,2,14,16,3,4,11,15,6,17,5,8,13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>OFXZFX</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[14,7,5,17,13,15,11,3,8,1,10,6,0,2,16,9,12,4]</td>\n",
       "      <td>[4,14,9,6,5,7,12,15,13,16,10,11,1,17,8,2,3,0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>PFQOZA</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[17,6,15,5,3,1,0,8,10,11,9,2,14,12,13,4,16,7]</td>\n",
       "      <td>[0,10,3,6,14,7,4,15,1,8,12,17,2,9,16,5,13,11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>TVTKOX</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[2,1,3,0,7,13,9,4,5,14,16,17,11,10,8,6,15,12]</td>\n",
       "      <td>[4,6,0,16,14,10,8,5,2,12,7,15,3,1,13,17,9,11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>WDXOXF</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[9,6,10,3,7,16,15,11,12,17,1,5,14,13,8,0,4,2]</td>\n",
       "      <td>[16,6,8,17,15,11,14,4,1,3,12,13,2,7,0,9,10,5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>AIARTT</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[3,11,2,14,10,5,9,17,12,1,7,15,8,4,13,0,6,16]</td>\n",
       "      <td>[15,14,0,3,8,6,5,12,13,1,7,4,16,17,11,2,9,10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>BFUADZ</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[3,17,6,10,0,1,8,9,12,14,2,4,13,7,15,5,16,11]</td>\n",
       "      <td>[3,2,9,17,10,11,15,12,1,8,7,5,16,13,0,4,14,6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>EHUNMG</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[14,4,9,0,17,7,11,10,13,15,1,2,6,5,16,3,8,12]</td>\n",
       "      <td>[11,17,4,6,0,5,12,13,1,2,16,8,7,14,9,15,3,10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>GYTTVS</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[8,0,1,13,14,5,11,6,16,12,10,15,4,9,3,7,2,17]</td>\n",
       "      <td>[14,11,7,13,2,10,4,17,6,1,9,3,15,5,0,8,12,16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>KSXGOZ</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[6,4,11,17,10,1,15,14,13,5,0,16,2,12,7,8,3,9]</td>\n",
       "      <td>[11,15,2,7,4,14,3,17,6,9,1,8,16,0,5,10,12,13]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID access_token  current_phase detector explainer  \\\n",
       "0    1       YOEMSM             -1     None      None   \n",
       "1    2       LDJVYN             -1     None      None   \n",
       "2    3       DDYXJD             -1     None      None   \n",
       "3    4       KHGHUI             -1     None      None   \n",
       "4    5       LIQXER             -1     None      None   \n",
       "5    6       ZLWEGL             -1     None      None   \n",
       "6    7       YOBXBC             -1     None      None   \n",
       "7    8       LKKCKR             -1     None      None   \n",
       "8    9       FXPIKS             -1     None      None   \n",
       "9   10       WYBNGV             -1     None      None   \n",
       "10  11       UBEKJT             -1     None      None   \n",
       "11  12       AQVGKB             -1     None      None   \n",
       "12  13       JRHLOX             -1     None      None   \n",
       "13  14       UJLPKI             -1     None      None   \n",
       "14  15       CAPYDK             -1     None      None   \n",
       "15  16       PLZDRA             -1     None      None   \n",
       "16  17       OZJPSK             -1     None      None   \n",
       "17  18       XNVNLA             -1     None      None   \n",
       "18  19       OFXZFX             -1     None      None   \n",
       "19  20       PFQOZA             -1     None      None   \n",
       "20  21       TVTKOX             -1     None      None   \n",
       "21  22       WDXOXF             -1     None      None   \n",
       "22  23       AIARTT             -1     None      None   \n",
       "23  24       BFUADZ             -1     None      None   \n",
       "24  25       EHUNMG             -1     None      None   \n",
       "25  26       GYTTVS             -1     None      None   \n",
       "26  27       KSXGOZ             -1     None      None   \n",
       "\n",
       "                                 document_order_a  \\\n",
       "0   [12,11,1,6,16,15,2,9,13,8,0,4,14,7,17,5,3,10]   \n",
       "1   [11,4,15,1,10,14,2,13,5,8,7,16,6,0,9,3,17,12]   \n",
       "2   [6,4,8,9,5,14,0,13,15,12,10,16,7,1,3,2,17,11]   \n",
       "3   [8,16,6,4,9,7,17,1,12,0,2,13,11,15,10,5,3,14]   \n",
       "4   [2,1,13,8,6,12,15,14,7,4,0,17,3,11,9,10,16,5]   \n",
       "5   [10,2,1,3,0,5,15,17,16,13,11,9,14,4,12,6,7,8]   \n",
       "6   [12,3,17,14,11,2,9,7,8,4,1,16,6,5,15,10,0,13]   \n",
       "7   [5,15,3,11,1,0,6,2,10,12,16,17,14,4,13,9,8,7]   \n",
       "8   [5,8,9,0,15,2,14,17,16,1,4,12,7,11,3,6,13,10]   \n",
       "9   [3,5,17,10,13,2,6,1,16,14,15,12,4,11,0,8,9,7]   \n",
       "10  [12,2,9,7,6,17,4,10,14,8,13,1,3,15,0,11,16,5]   \n",
       "11  [14,0,3,5,15,8,9,11,7,4,17,13,6,10,1,12,16,2]   \n",
       "12  [15,6,17,7,3,13,9,16,12,14,1,10,2,11,8,0,4,5]   \n",
       "13  [8,14,13,0,6,2,9,1,16,5,3,10,17,12,15,4,11,7]   \n",
       "14  [2,17,3,11,14,4,1,8,5,15,13,0,10,16,9,7,6,12]   \n",
       "15  [7,17,1,9,6,0,11,12,15,4,14,3,8,5,10,16,2,13]   \n",
       "16  [6,4,3,2,16,11,17,8,12,7,1,9,10,13,15,14,5,0]   \n",
       "17  [13,14,6,15,7,10,17,0,9,1,16,2,3,12,11,4,8,5]   \n",
       "18  [14,7,5,17,13,15,11,3,8,1,10,6,0,2,16,9,12,4]   \n",
       "19  [17,6,15,5,3,1,0,8,10,11,9,2,14,12,13,4,16,7]   \n",
       "20  [2,1,3,0,7,13,9,4,5,14,16,17,11,10,8,6,15,12]   \n",
       "21  [9,6,10,3,7,16,15,11,12,17,1,5,14,13,8,0,4,2]   \n",
       "22  [3,11,2,14,10,5,9,17,12,1,7,15,8,4,13,0,6,16]   \n",
       "23  [3,17,6,10,0,1,8,9,12,14,2,4,13,7,15,5,16,11]   \n",
       "24  [14,4,9,0,17,7,11,10,13,15,1,2,6,5,16,3,8,12]   \n",
       "25  [8,0,1,13,14,5,11,6,16,12,10,15,4,9,3,7,2,17]   \n",
       "26  [6,4,11,17,10,1,15,14,13,5,0,16,2,12,7,8,3,9]   \n",
       "\n",
       "                                 document_order_b  \n",
       "0   [15,14,0,10,9,7,13,8,3,5,16,2,4,12,1,6,17,11]  \n",
       "1   [2,10,6,1,5,4,15,12,16,8,3,17,9,11,7,14,0,13]  \n",
       "2   [10,15,17,1,0,11,9,2,13,7,16,14,3,4,5,12,6,8]  \n",
       "3   [9,15,6,3,13,14,16,12,2,17,4,1,7,8,10,0,5,11]  \n",
       "4   [12,14,15,4,6,13,3,8,2,11,16,9,1,0,5,10,7,17]  \n",
       "5   [14,17,6,1,8,12,5,13,11,3,9,7,16,4,0,10,2,15]  \n",
       "6   [8,15,3,13,4,10,6,17,5,0,12,11,1,9,14,7,2,16]  \n",
       "7   [2,9,16,15,1,6,3,17,7,11,0,13,4,8,10,5,12,14]  \n",
       "8   [0,4,2,7,6,3,13,10,1,5,8,15,12,11,9,17,16,14]  \n",
       "9   [14,2,15,13,1,12,17,4,0,9,3,7,6,8,11,10,16,5]  \n",
       "10  [7,2,9,16,12,5,6,3,11,4,13,10,8,14,15,1,17,0]  \n",
       "11  [6,4,17,8,3,15,2,5,13,12,16,1,9,14,0,11,7,10]  \n",
       "12  [9,3,8,2,5,15,7,6,0,11,14,12,17,10,13,1,16,4]  \n",
       "13  [7,6,11,12,5,4,8,16,14,13,3,2,9,1,0,17,10,15]  \n",
       "14  [0,1,13,7,14,6,2,3,12,8,4,10,17,15,5,9,16,11]  \n",
       "15  [16,2,7,15,1,11,5,0,3,10,4,12,14,13,9,8,6,17]  \n",
       "16  [2,10,15,5,11,17,6,16,9,1,3,0,7,13,4,14,12,8]  \n",
       "17  [7,0,10,1,9,12,2,14,16,3,4,11,15,6,17,5,8,13]  \n",
       "18  [4,14,9,6,5,7,12,15,13,16,10,11,1,17,8,2,3,0]  \n",
       "19  [0,10,3,6,14,7,4,15,1,8,12,17,2,9,16,5,13,11]  \n",
       "20  [4,6,0,16,14,10,8,5,2,12,7,15,3,1,13,17,9,11]  \n",
       "21  [16,6,8,17,15,11,14,4,1,3,12,13,2,7,0,9,10,5]  \n",
       "22  [15,14,0,3,8,6,5,12,13,1,7,4,16,17,11,2,9,10]  \n",
       "23  [3,2,9,17,10,11,15,12,1,8,7,5,16,13,0,4,14,6]  \n",
       "24  [11,17,4,6,0,5,12,13,1,2,16,8,7,14,9,15,3,10]  \n",
       "25  [14,11,7,13,2,10,4,17,6,1,9,3,15,5,0,8,12,16]  \n",
       "26  [11,15,2,7,4,14,3,17,6,9,1,8,16,0,5,10,12,13]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_study = pd.read_csv(USER_STUDY_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Database\n",
    "If `FILL_DATABASE` is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run_user.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_user.py\n",
    "\n",
    "def run_user(idx, user, url, df_user_study):\n",
    "    n_learn = 16\n",
    "    n_eval = 16\n",
    "    n_users = 10\n",
    "\n",
    "    mu_got_it_right_pre=0.5\n",
    "    sigma_got_it_right_pre=0.05\n",
    "    mu_gain = 0.2\n",
    "    sigma_gain = 0.1\n",
    "\n",
    "    def guess(detector_label,p):\n",
    "        return detector_label if bool(np.random.choice([0,1],p=[1-p, p])) else not detector_label\n",
    "\n",
    "    import requests\n",
    "    import json\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    user_dist_without = lambda : np.clip(np.random.normal(mu_got_it_right_pre, sigma_got_it_right_pre, 1)[0], 0,1)\n",
    "    user_dist_gain = lambda : np.clip(np.random.normal(mu_gain, sigma_gain, 1)[0], -1,1)\n",
    "  \n",
    "    res = requests.get(url+\"/auth/\"+ user[\"access_token\"])\n",
    "\n",
    "    print(res.text)\n",
    "    auth_token = json.loads(res.text)\n",
    "    headers = {'Content-Type': 'application/json','Authorization': \"Bearer \"+auth_token, \"Content-Type\": \"application/json\",}\n",
    "\n",
    "    requests.post(url+\"/api/submitParticipantInfo\", json={\n",
    "    \"has_seen_explanation_methods_before\": \"yes\",\n",
    "    \"has_seen_OTHERS_before\": \"yes\",\n",
    "    \"level_of_expertise\": \"is-researcher-explainability\",\n",
    "    \"familiarity_with_chatgpt\": \"occasional-use\",\n",
    "    \"prefers_monochromatic_methods\": \"yes\" if user[\"access_token\"] == \"DDEBUG\" else \"no\"\n",
    "    }, headers=headers)\n",
    "    # go to phase 2\n",
    "    requests.post(url+\"/api/completeCurrentPhase\", json={\"expected\": 0}, headers=headers)\n",
    "    requests.post(url+\"/api/completeCurrentPhase\", json={\"expected\": 1}, headers=headers)\n",
    "    requests.post(url+\"/api/completeCurrentPhase\", json={\"expected\": 2}, headers=headers)\n",
    "\n",
    "    res = requests.get(url+\"/api/state\", headers=headers)\n",
    "    state = json.loads(res.text)\n",
    "\n",
    "    # user_df = pd.read_sql_query(\"SELECT * FROM users\", connection) # update as group is assigned now\n",
    "    # user = user_df.iloc[idx]\n",
    "   # print(user[[\"detector\", \"explainer\"]])\n",
    "    # return state\n",
    "    df_user_documents = df_user_study.loc[df_user_study.groupby(\"Detector\").groups[state[\"detector\"]],:].reset_index(drop=True)\n",
    "    for doc_nr, row in df_user_documents.iterrows():\n",
    "        p_without = user_dist_without()\n",
    "        requests.post(url+\"/api/submitPhase2\", json={\"ID\": doc_nr, \"label\": guess(row[\"f(b)\"], p_without)}, headers=headers)\n",
    "    requests.post(url+\"/api/completeCurrentPhase\", json={\"expected\": 3}, headers=headers)\n",
    "\n",
    "    for doc_nr, row in df_user_documents.iterrows():\n",
    "        json_ = {\"lickert-q{}-{}\".format(question_nr, doc_nr): str(np.random.choice([1,2,3,4,5], p=[0.1,0.2,0.1,0.4,0.2])) for question_nr in range(1,4)}\n",
    "        json_[\"document_nr\"] = doc_nr\n",
    "        requests.post(url+\"/api/submitPhase3\", json=json_, headers=headers)\n",
    "\n",
    "    requests.post(url+\"/api/completeCurrentPhase\", json={\"expected\": 4}, headers=headers)\n",
    "    for doc_nr, row in df_user_documents.iterrows():\n",
    "        p_with = np.clip(p_without + user_dist_gain(), 0,1)\n",
    "        requests.post(url+\"/api/submitPhase4\", json={\"ID\": doc_nr, \"label\": guess(row[\"f(b)\"], p_with)}, headers=headers)\n",
    "    requests.post(url+\"/api/completeCurrentPhase\", json={\"expected\": 5}, headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "probabilities do not sum to 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\multiprocess\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\multiprocess\\pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\loris\\thesis\\run_user.py\", line 54, in run_user\n    json_ = {\"lickert-q{}-{}\".format(question_nr, doc_nr): str(np.random.choice([1,2,3,4,5], p=[0.1,0.2,0.1,0.4,0.3])) for question_nr in range(1,4)}\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\loris\\thesis\\run_user.py\", line 54, in <dictcomp>\n    json_ = {\"lickert-q{}-{}\".format(question_nr, doc_nr): str(np.random.choice([1,2,3,4,5], p=[0.1,0.2,0.1,0.4,0.3])) for question_nr in range(1,4)}\n                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"numpy\\\\random\\\\mtrand.pyx\", line 974, in numpy.random.mtrand.RandomState.choice\nValueError: probabilities do not sum to 1\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m mock_user_data \u001b[38;5;241m=\u001b[39m [(idx, user, server_url, df_user_study) \u001b[38;5;28;01mfor\u001b[39;00m idx, user \u001b[38;5;129;01min\u001b[39;00m user_df\u001b[38;5;241m.\u001b[39miterrows()]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(max_pool) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[1;32m---> 11\u001b[0m     pool_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tqdm(\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_user\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmock_user_data\u001b[49m\u001b[43m)\u001b[49m,total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(mock_user_data)))    \n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(pool_outputs)\n",
      "File \u001b[1;32mc:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\multiprocess\\pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\multiprocess\\pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[1;31mValueError\u001b[0m: probabilities do not sum to 1"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from multiprocess import Pool\n",
    "from run_user import run_user\n",
    "\n",
    "\n",
    "if FILL_DATABASE:\n",
    "    max_pool = 30\n",
    "    mock_user_data = [(idx, user, server_url, df_user_study) for idx, user in user_df.iterrows()]\n",
    "\n",
    "    with Pool(max_pool) as p:\n",
    "        pool_outputs = list(tqdm(p.starmap(run_user,mock_user_data),total=len(mock_user_data)))    \n",
    "    print(pool_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_sql_query(\"SELECT * FROM users\", connection) # update df from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: ID, dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.groupby([\"detector\", \"explainer\"])[\"ID\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>access_token</th>\n",
       "      <th>current_phase</th>\n",
       "      <th>detector</th>\n",
       "      <th>explainer</th>\n",
       "      <th>document_order_a</th>\n",
       "      <th>document_order_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, access_token, current_phase, detector, explainer, document_order_a, document_order_b]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_metrics(df_user_responses, df_user_study):\n",
    "    detector = df_user_responses.iloc[0][\"detector\"]\n",
    "    # explainer = df_user_responses.iloc[0][\"explainer\"]\n",
    "    df_user_documents = df_user_study.loc[df_user_study.groupby(\"Detector\").groups[detector],:].reset_index(drop=True)\n",
    "    detector_predictions = df_user_documents[\"f(b)\"].astype(bool)\n",
    "\n",
    "    user_responses = df_user_responses.loc[df_user_responses.groupby(\"document_nr\")[\"timestamp\"].idxmax()].set_index(\"document_nr\")[\"label\"].astype(bool) # only keep most recent response\n",
    "    TP = ((detector_predictions) & (user_responses)).sum()\n",
    "    FP = ((~detector_predictions) & (user_responses)).sum()\n",
    "\n",
    "    TN = ((~detector_predictions) & (~user_responses)).sum()\n",
    "    FN = ((detector_predictions) & (~user_responses)).sum()\n",
    "\n",
    "    acc = (TP+TN) / (TP+FP+TN+FN)\n",
    "    print(\"acc\", acc)\n",
    "    print(\"TP\", TP)\n",
    "    print(\"FP\", FP)\n",
    "    print(\"TN\", TN)\n",
    "    print(\"FN\", FN)\n",
    "\n",
    "\n",
    "    assert sum([TP,FP,TN,FN]) == len(detector_predictions), \"Check that input is bool\"\n",
    "    assert (acc ==(user_responses == detector_predictions).sum() / len(detector_predictions)), \"Check that input is bool: acc\"\n",
    "\n",
    "    return pd.DataFrame([(TP,TN,FP,FN, acc)], columns=[\"TP\",\"TN\",\"FP\",\"FN\", \"User Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = user_df.set_index(\"ID\").rename_axis(\"user_id\")[[\"explainer\", \"detector\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phase_2 = pd.read_sql_query(\"SELECT responses_phase_2.*, users.detector, users.explainer FROM responses_phase_2 INNER JOIN users ON responses_phase_2.user_id = users.ID\", connection)\n",
    "df_phase_4 = pd.read_sql_query(\"SELECT responses_phase_4.*, users.detector, users.explainer FROM responses_phase_4 INNER JOIN users ON responses_phase_4.user_id = users.ID\", connection)\n",
    "\n",
    "metrics_phase_4 = df_phase_4.groupby([\"user_id\"]).apply(lambda df_user_responses : user_metrics(df_user_responses,df_user_study))\n",
    "metrics_phase_2 = df_phase_2.groupby([\"user_id\"]).apply(lambda df_user_responses : user_metrics(df_user_responses,df_user_study))\n",
    "\n",
    "\n",
    "difference = metrics_phase_4 - metrics_phase_2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['detector', 'explainer'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdifference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetector\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser Accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:10412\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[0;32m  10402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  10403\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[0;32m  10404\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10405\u001b[0m             other,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10410\u001b[0m             validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m  10411\u001b[0m         )\n\u001b[1;32m> 10412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10413\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m  10418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m  10419\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlsuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrsuffix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10420\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  10423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m  10424\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:183\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    170\u001b[0m         left_df,\n\u001b[0;32m    171\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:885\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[0;32m    883\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 885\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    888\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[1;32mc:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:837\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    834\u001b[0m left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft[:]\n\u001b[0;32m    835\u001b[0m right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright[:]\n\u001b[1;32m--> 837\u001b[0m llabels, rlabels \u001b[38;5;241m=\u001b[39m \u001b[43m_items_overlap_with_suffix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuffixes\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[0;32m    842\u001b[0m     \u001b[38;5;66;03m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[0;32m    843\u001b[0m     \u001b[38;5;66;03m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;66;03m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[0;32m    845\u001b[0m     lmgr \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m    846\u001b[0m         join_index,\n\u001b[0;32m    847\u001b[0m         left_indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    852\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    853\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2661\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[1;34m(left, right, suffixes)\u001b[0m\n\u001b[0;32m   2658\u001b[0m lsuffix, rsuffix \u001b[38;5;241m=\u001b[39m suffixes\n\u001b[0;32m   2660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lsuffix \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rsuffix:\n\u001b[1;32m-> 2661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns overlap but no suffix specified: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mto_rename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrenamer\u001b[39m(x, suffix: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2664\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2665\u001b[0m \u001b[38;5;124;03m    Rename the left and right indices.\u001b[39;00m\n\u001b[0;32m   2666\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[38;5;124;03m    x : renamed column name\u001b[39;00m\n\u001b[0;32m   2678\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['detector', 'explainer'], dtype='object')"
     ]
    }
   ],
   "source": [
    "difference.join(u).groupby([\"detector\"])[\"User Accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "explainer\n",
       "SHAP_Explainer    0.0\n",
       "Name: User Accuracy, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference.join(u).groupby([\"explainer\"])[\"User Accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "detector           explainer     \n",
       "DetectorDetectGPT  SHAP_Explainer    0.0\n",
       "Name: User Accuracy, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference.join(u).groupby([\"detector\", \"explainer\"])[\"User Accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([1], dtype='int64', name='user_id')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_phase_4.join(u).index.get_level_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_significant(row, props=''):\n",
    "  #  display(s)\n",
    "    styles = [''] * len(row)\n",
    "    styles[2] = 'font-weight: bold' if row[\"p value\"] <= 0.05 else ''\n",
    "    return styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregate_results(groupby, label, caption):\n",
    "    tvalues = []\n",
    "    pvalues = []\n",
    "    for name, group_2 in metrics_phase_2.join(u).groupby(groupby):\n",
    "        group_4 =  metrics_phase_4.join(u)[np.all(metrics_phase_4.join(u)[groupby].values == name, axis=1)]\n",
    "        tvalue, pvalue = ttest_ind(group_2[\"User Accuracy\"],group_4[\"User Accuracy\"])\n",
    "        tvalues.append(tvalue)\n",
    "        pvalues.append(pvalue)\n",
    "\n",
    "    df_aggregate_results = pd.DataFrame(difference.join(u).groupby(groupby)[\"User Accuracy\"].mean())\n",
    "\n",
    "    df_aggregate_results = df_aggregate_results.join(pd.DataFrame(metrics_phase_2.join(u).groupby(groupby)[\"User Accuracy\"].mean()).rename({\"User Accuracy\":\"Before\"}, axis=1))\n",
    "    df_aggregate_results = df_aggregate_results.join(pd.DataFrame(metrics_phase_4.join(u).groupby(groupby)[\"User Accuracy\"].mean()).rename({\"User Accuracy\":\"After\"}, axis=1))\n",
    "\n",
    "    df_aggregate_results[\"t value\"] = tvalues\n",
    "    df_aggregate_results[\"p value\"] = pvalues\n",
    "\n",
    "    df_aggregate_results.rename(columns={\"User Accuracy\":\"Increase in User Accuracy\"}, inplace=True)\n",
    "    df_aggregate_results = df_aggregate_results.reindex(sorted(df_aggregate_results.columns), axis=1)\n",
    "    result = df_aggregate_results.style.apply(highlight_significant, axis=1)\\\n",
    "        .map_index(lambda v: \"rotatebox:{45}--rwrap;\", level=0, axis=1).format(precision=2).hide([\"t value\"], axis=1).format_index(escape=\"latex\", axis=0)\n",
    "    latex_output.append(result.to_latex(environment=\"longtable\", \n",
    "                                        convert_css=True, \n",
    "                                        clines=\"all;data\", \n",
    "                                        hrules=True, \n",
    "                                        caption=caption, \n",
    "                                        label=label))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:7030: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  svar = ((n1 - 1) * v1 + (n2 - 1) * v2) / df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0e98d_level0_col0, #T_0e98d_level0_col1, #T_0e98d_level0_col2, #T_0e98d_level0_col3 {\n",
       "  rotatebox: {45}--rwrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0e98d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0e98d_level0_col0\" class=\"col_heading level0 col0\" >After</th>\n",
       "      <th id=\"T_0e98d_level0_col1\" class=\"col_heading level0 col1\" >Before</th>\n",
       "      <th id=\"T_0e98d_level0_col2\" class=\"col_heading level0 col2\" >Increase in User Accuracy</th>\n",
       "      <th id=\"T_0e98d_level0_col3\" class=\"col_heading level0 col3\" >p value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >detector</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0e98d_level0_row0\" class=\"row_heading level0 row0\" >DetectorDetectGPT</th>\n",
       "      <td id=\"T_0e98d_row0_col0\" class=\"data row0 col0\" >0.89</td>\n",
       "      <td id=\"T_0e98d_row0_col1\" class=\"data row0 col1\" >0.89</td>\n",
       "      <td id=\"T_0e98d_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_0e98d_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b7d9a99550>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_aggregate_results([\"detector\"], \"resultsuserstudydetector\", \"Results aggregated by detector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:7030: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  svar = ((n1 - 1) * v1 + (n2 - 1) * v2) / df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3cc41_level0_col0, #T_3cc41_level0_col1, #T_3cc41_level0_col2, #T_3cc41_level0_col3 {\n",
       "  rotatebox: {45}--rwrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3cc41\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3cc41_level0_col0\" class=\"col_heading level0 col0\" >After</th>\n",
       "      <th id=\"T_3cc41_level0_col1\" class=\"col_heading level0 col1\" >Before</th>\n",
       "      <th id=\"T_3cc41_level0_col2\" class=\"col_heading level0 col2\" >Increase in User Accuracy</th>\n",
       "      <th id=\"T_3cc41_level0_col3\" class=\"col_heading level0 col3\" >p value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >explainer</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3cc41_level0_row0\" class=\"row_heading level0 row0\" >SHAP\\_Explainer</th>\n",
       "      <td id=\"T_3cc41_row0_col0\" class=\"data row0 col0\" >0.89</td>\n",
       "      <td id=\"T_3cc41_row0_col1\" class=\"data row0 col1\" >0.89</td>\n",
       "      <td id=\"T_3cc41_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_3cc41_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b7db9e5d50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_aggregate_results([\"explainer\"], \"resultsuserstudyexplainer\", \"Results aggregated by explainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:7030: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  svar = ((n1 - 1) * v1 + (n2 - 1) * v2) / df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a9fd2_level0_col0, #T_a9fd2_level0_col1, #T_a9fd2_level0_col2, #T_a9fd2_level0_col3 {\n",
       "  rotatebox: {45}--rwrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a9fd2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a9fd2_level0_col0\" class=\"col_heading level0 col0\" >After</th>\n",
       "      <th id=\"T_a9fd2_level0_col1\" class=\"col_heading level0 col1\" >Before</th>\n",
       "      <th id=\"T_a9fd2_level0_col2\" class=\"col_heading level0 col2\" >Increase in User Accuracy</th>\n",
       "      <th id=\"T_a9fd2_level0_col3\" class=\"col_heading level0 col3\" >p value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >explainer</th>\n",
       "      <th class=\"index_name level1\" >detector</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a9fd2_level0_row0\" class=\"row_heading level0 row0\" >SHAP\\_Explainer</th>\n",
       "      <th id=\"T_a9fd2_level1_row0\" class=\"row_heading level1 row0\" >DetectorDetectGPT</th>\n",
       "      <td id=\"T_a9fd2_row0_col0\" class=\"data row0 col0\" >0.89</td>\n",
       "      <td id=\"T_a9fd2_row0_col1\" class=\"data row0 col1\" >0.89</td>\n",
       "      <td id=\"T_a9fd2_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_a9fd2_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b7dba28610>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_aggregate_results([\"explainer\", \"detector\"], \"resultsuserstudyexplainerdetector\", \"Results aggregated by explainer and detector pairing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lickert Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>document_nr</th>\n",
       "      <th>question_nr</th>\n",
       "      <th>detector</th>\n",
       "      <th>explainer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-03-02 23:13:59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-02 23:14:13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-03-02 23:14:13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-03-02 23:14:47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2024-03-02 23:14:47</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>281</td>\n",
       "      <td>2024-03-02 23:55:19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>282</td>\n",
       "      <td>2024-03-02 23:55:19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>283</td>\n",
       "      <td>2024-03-02 23:55:19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>284</td>\n",
       "      <td>2024-03-02 23:55:19</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>285</td>\n",
       "      <td>2024-03-02 23:55:19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID            timestamp  label  user_id  document_nr  question_nr  \\\n",
       "0      1  2024-03-02 23:13:59      2        1           12            1   \n",
       "1      2  2024-03-02 23:14:13      2        1           12            1   \n",
       "2      3  2024-03-02 23:14:13      4        1           12            2   \n",
       "3      4  2024-03-02 23:14:47      2        1           12            1   \n",
       "4      5  2024-03-02 23:14:47      4        1           12            3   \n",
       "..   ...                  ...    ...      ...          ...          ...   \n",
       "280  281  2024-03-02 23:55:19      4        1           10            1   \n",
       "281  282  2024-03-02 23:55:19      2        1           10            5   \n",
       "282  283  2024-03-02 23:55:19      4        1           10            3   \n",
       "283  284  2024-03-02 23:55:19      3        1           10            4   \n",
       "284  285  2024-03-02 23:55:19      4        1           10            2   \n",
       "\n",
       "              detector       explainer  \n",
       "0    DetectorDetectGPT  SHAP_Explainer  \n",
       "1    DetectorDetectGPT  SHAP_Explainer  \n",
       "2    DetectorDetectGPT  SHAP_Explainer  \n",
       "3    DetectorDetectGPT  SHAP_Explainer  \n",
       "4    DetectorDetectGPT  SHAP_Explainer  \n",
       "..                 ...             ...  \n",
       "280  DetectorDetectGPT  SHAP_Explainer  \n",
       "281  DetectorDetectGPT  SHAP_Explainer  \n",
       "282  DetectorDetectGPT  SHAP_Explainer  \n",
       "283  DetectorDetectGPT  SHAP_Explainer  \n",
       "284  DetectorDetectGPT  SHAP_Explainer  \n",
       "\n",
       "[285 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phase_3 = pd.read_sql_query(\"SELECT responses_phase_3.*, users.detector, users.explainer FROM responses_phase_3 INNER JOIN users ON responses_phase_3.user_id = users.ID\", connection)\n",
    "df_phase_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>detector</th>\n",
       "      <th>explainer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>document_nr</th>\n",
       "      <th>question_nr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>SHAP_Explainer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 label           detector       explainer\n",
       "user_id document_nr question_nr                                          \n",
       "1       0           1                3  DetectorDetectGPT  SHAP_Explainer\n",
       "        1           1                4  DetectorDetectGPT  SHAP_Explainer\n",
       "        2           1                2  DetectorDetectGPT  SHAP_Explainer\n",
       "        3           1                4  DetectorDetectGPT  SHAP_Explainer\n",
       "        4           1                3  DetectorDetectGPT  SHAP_Explainer\n",
       "...                                ...                ...             ...\n",
       "        13          5                2  DetectorDetectGPT  SHAP_Explainer\n",
       "        14          5                2  DetectorDetectGPT  SHAP_Explainer\n",
       "        15          5                3  DetectorDetectGPT  SHAP_Explainer\n",
       "        16          5                2  DetectorDetectGPT  SHAP_Explainer\n",
       "        17          5                3  DetectorDetectGPT  SHAP_Explainer\n",
       "\n",
       "[90 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_responses = df_phase_3.loc[df_phase_3.groupby([\"user_id\", \"question_nr\", \"document_nr\"])[\"timestamp\"].idxmax()].set_index([\"user_id\", \"document_nr\", \"question_nr\"]).drop([\"timestamp\", \"ID\"], axis=1)\n",
    "user_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detector</th>\n",
       "      <th>explainer</th>\n",
       "      <th>question_nr</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">DetectorDetectGPT</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">SHAP_Explainer</th>\n",
       "      <th>1</th>\n",
       "      <td>3.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 label\n",
       "detector          explainer      question_nr          \n",
       "DetectorDetectGPT SHAP_Explainer 1            3.277778\n",
       "                                 2            3.388889\n",
       "                                 3            3.222222\n",
       "                                 4            3.277778\n",
       "                                 5            2.555556"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_responses.groupby([\"detector\", \"explainer\", \"question_nr\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "There has to be at least one unit with values assigned by at least two coders.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     cannonical_form \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mpivot(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion_nr\u001b[39m\u001b[38;5;124m\"\u001b[39m], values\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m], index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument_nr\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# print(cannonical_form)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# print()\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     alpha_values\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;241m*\u001b[39mname, \u001b[43mkrippendorff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcannonical_form\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel_of_measurement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mordinal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m))\n\u001b[0;32m      8\u001b[0m df_krippendorff_alpha \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(alpha_values, columns\u001b[38;5;241m=\u001b[39mgroupby \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      9\u001b[0m df_krippendorff_alpha\u001b[38;5;241m.\u001b[39mgroupby(groupby[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mdescribe()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\krippendorff\\krippendorff.py:352\u001b[0m, in \u001b[0;36malpha\u001b[1;34m(reliability_data, value_counts, value_domain, level_of_measurement, dtype)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere has to be more than one value in the domain.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (value_counts\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere has to be at least one unit with values assigned by at least two coders.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    354\u001b[0m dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(dtype, np\u001b[38;5;241m.\u001b[39minexact):\n",
      "\u001b[1;31mValueError\u001b[0m: There has to be at least one unit with values assigned by at least two coders."
     ]
    }
   ],
   "source": [
    "groupby = [ \"explainer\", \"document_nr\"]\n",
    "alpha_values = []\n",
    "for name, group in user_responses.groupby(groupby):\n",
    "    cannonical_form = group.reset_index().pivot(columns=[\"question_nr\"], values=[\"label\"], index=[\"user_id\", \"document_nr\"])\n",
    "    # print(cannonical_form)\n",
    "    # print()\n",
    "    alpha_values.append((*name, krippendorff.alpha(cannonical_form, level_of_measurement=\"ordinal\")))\n",
    "df_krippendorff_alpha = pd.DataFrame(alpha_values, columns=groupby + [\"alpha\"])\n",
    "df_krippendorff_alpha.groupby(groupby[0:-1]).describe()[\"alpha\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_significant(row, props=''):\n",
    "  #  display(s)\n",
    "    styles = [''] * len(row)\n",
    "    styles[0] = 'font-weight: bold' if row[\"p value\"] <= 0.05 else ''\n",
    "    return styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregate_results_lickert(groupby, label, caption):\n",
    "    tvalues = []\n",
    "    pvalues = []\n",
    "    for name, group in user_responses.groupby(groupby):\n",
    "        tvalue, pvalue = ttest_1samp(group[\"label\"], popmean=3)\n",
    "        tvalues.append(tvalue)\n",
    "        pvalues.append(pvalue)\n",
    "        \n",
    "        \n",
    "\n",
    "    df_aggregate_results = pd.DataFrame(user_responses.groupby(groupby)[\"label\"].mean())\n",
    "\n",
    "\n",
    "    df_aggregate_results[\"t value\"] = tvalues\n",
    "    df_aggregate_results[\"p value\"] = pvalues\n",
    "\n",
    "    df_aggregate_results = df_aggregate_results.reindex(sorted(df_aggregate_results.columns), axis=1)\n",
    "    result = df_aggregate_results.style.apply(highlight_significant, axis=1)\\\n",
    "        .map_index(lambda v: \"rotatebox:{45}--rwrap;\", level=0, axis=1).format(precision=2).hide([\"t value\"], axis=1).format_index(escape=\"latex\", axis=0)\n",
    "    latex_output.append(result.to_latex(environment=\"longtable\", \n",
    "                                        convert_css=True, \n",
    "                                        clines=\"all;data\", \n",
    "                                        hrules=True, \n",
    "                                        caption=caption, \n",
    "                                        label=label))\n",
    "\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_16d94_row4_col0, #T_16d94_row6_col0 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_16d94_level0_col0, #T_16d94_level0_col1 {\n",
       "  rotatebox: {45}--rwrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_16d94\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_16d94_level0_col0\" class=\"col_heading level0 col0\" >label</th>\n",
       "      <th id=\"T_16d94_level0_col1\" class=\"col_heading level0 col1\" >p value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >detector</th>\n",
       "      <th class=\"index_name level1\" >explainer</th>\n",
       "      <th class=\"index_name level2\" >question_nr</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_16d94_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"5\">DetectorGuo</th>\n",
       "      <th id=\"T_16d94_level1_row0\" class=\"row_heading level1 row0\" rowspan=\"5\">SHAP\\_Explainer</th>\n",
       "      <th id=\"T_16d94_level2_row0\" class=\"row_heading level2 row0\" >1</th>\n",
       "      <td id=\"T_16d94_row0_col0\" class=\"data row0 col0\" >3.50</td>\n",
       "      <td id=\"T_16d94_row0_col1\" class=\"data row0 col1\" >0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16d94_level2_row1\" class=\"row_heading level2 row1\" >2</th>\n",
       "      <td id=\"T_16d94_row1_col0\" class=\"data row1 col0\" >3.33</td>\n",
       "      <td id=\"T_16d94_row1_col1\" class=\"data row1 col1\" >0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16d94_level2_row2\" class=\"row_heading level2 row2\" >3</th>\n",
       "      <td id=\"T_16d94_row2_col0\" class=\"data row2 col0\" >3.42</td>\n",
       "      <td id=\"T_16d94_row2_col1\" class=\"data row2 col1\" >0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16d94_level2_row3\" class=\"row_heading level2 row3\" >4</th>\n",
       "      <td id=\"T_16d94_row3_col0\" class=\"data row3 col0\" >3.25</td>\n",
       "      <td id=\"T_16d94_row3_col1\" class=\"data row3 col1\" >0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16d94_level2_row4\" class=\"row_heading level2 row4\" >5</th>\n",
       "      <td id=\"T_16d94_row4_col0\" class=\"data row4 col0\" >3.42</td>\n",
       "      <td id=\"T_16d94_row4_col1\" class=\"data row4 col1\" >0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16d94_level0_row5\" class=\"row_heading level0 row5\" rowspan=\"5\">DetectorRadford</th>\n",
       "      <th id=\"T_16d94_level1_row5\" class=\"row_heading level1 row5\" rowspan=\"5\">SHAP\\_Explainer</th>\n",
       "      <th id=\"T_16d94_level2_row5\" class=\"row_heading level2 row5\" >1</th>\n",
       "      <td id=\"T_16d94_row5_col0\" class=\"data row5 col0\" >3.33</td>\n",
       "      <td id=\"T_16d94_row5_col1\" class=\"data row5 col1\" >0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16d94_level2_row6\" class=\"row_heading level2 row6\" >2</th>\n",
       "      <td id=\"T_16d94_row6_col0\" class=\"data row6 col0\" >3.58</td>\n",
       "      <td id=\"T_16d94_row6_col1\" class=\"data row6 col1\" >0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16d94_level2_row7\" class=\"row_heading level2 row7\" >3</th>\n",
       "      <td id=\"T_16d94_row7_col0\" class=\"data row7 col0\" >3.42</td>\n",
       "      <td id=\"T_16d94_row7_col1\" class=\"data row7 col1\" >0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16d94_level2_row8\" class=\"row_heading level2 row8\" >4</th>\n",
       "      <td id=\"T_16d94_row8_col0\" class=\"data row8 col0\" >3.17</td>\n",
       "      <td id=\"T_16d94_row8_col1\" class=\"data row8 col1\" >0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16d94_level2_row9\" class=\"row_heading level2 row9\" >5</th>\n",
       "      <td id=\"T_16d94_row9_col0\" class=\"data row9 col0\" >2.92</td>\n",
       "      <td id=\"T_16d94_row9_col1\" class=\"data row9 col1\" >0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2adcd6d8790>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_aggregate_results_lickert([\"detector\", \"explainer\", \"question_nr\"], \"lickert-detector-explainer\",\"Lickert Scale Items on detector-explainer level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1e2b2_level0_col0, #T_1e2b2_level0_col1 {\n",
       "  rotatebox: {45}--rwrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1e2b2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1e2b2_level0_col0\" class=\"col_heading level0 col0\" >label</th>\n",
       "      <th id=\"T_1e2b2_level0_col1\" class=\"col_heading level0 col1\" >p value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >explainer</th>\n",
       "      <th class=\"index_name level1\" >question_nr</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1e2b2_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"5\">SHAP\\_Explainer</th>\n",
       "      <th id=\"T_1e2b2_level1_row0\" class=\"row_heading level1 row0\" >1</th>\n",
       "      <td id=\"T_1e2b2_row0_col0\" class=\"data row0 col0\" >3.42</td>\n",
       "      <td id=\"T_1e2b2_row0_col1\" class=\"data row0 col1\" >0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1e2b2_level1_row1\" class=\"row_heading level1 row1\" >2</th>\n",
       "      <td id=\"T_1e2b2_row1_col0\" class=\"data row1 col0\" >3.46</td>\n",
       "      <td id=\"T_1e2b2_row1_col1\" class=\"data row1 col1\" >0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1e2b2_level1_row2\" class=\"row_heading level1 row2\" >3</th>\n",
       "      <td id=\"T_1e2b2_row2_col0\" class=\"data row2 col0\" >3.42</td>\n",
       "      <td id=\"T_1e2b2_row2_col1\" class=\"data row2 col1\" >0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1e2b2_level1_row3\" class=\"row_heading level1 row3\" >4</th>\n",
       "      <td id=\"T_1e2b2_row3_col0\" class=\"data row3 col0\" >3.21</td>\n",
       "      <td id=\"T_1e2b2_row3_col1\" class=\"data row3 col1\" >0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1e2b2_level1_row4\" class=\"row_heading level1 row4\" >5</th>\n",
       "      <td id=\"T_1e2b2_row4_col0\" class=\"data row4 col0\" >3.17</td>\n",
       "      <td id=\"T_1e2b2_row4_col1\" class=\"data row4 col1\" >0.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2adcb508a90>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_aggregate_results_lickert([ \"explainer\", \"question_nr\"], \"lickert-explainer\",\"Lickert Scale Items on explainer level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{longtable}{lrrrr}\n",
      "\\caption{Results aggregated by detector} \\label{resultsuserstudydetector} \\\\\n",
      "\\toprule\n",
      " & \\rotatebox{45}{After} & \\rotatebox{45}{Before} & \\rotatebox{45}{Increase in User Accuracy} & \\rotatebox{45}{p value} \\\\\n",
      "detector &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\endfirsthead\n",
      "\\caption[]{Results aggregated by detector} \\\\\n",
      "\\toprule\n",
      " & \\rotatebox{45}{After} & \\rotatebox{45}{Before} & \\rotatebox{45}{Increase in User Accuracy} & \\rotatebox{45}{p value} \\\\\n",
      "detector &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\endhead\n",
      "\\midrule\n",
      "\\multicolumn{5}{r}{Continued on next page} \\\\\n",
      "\\midrule\n",
      "\\endfoot\n",
      "\\bottomrule\n",
      "\\endlastfoot\n",
      "DetectorGuo & 0.75 & 0.67 & 0.08 & nan \\\\\n",
      "\\cline{1-5}\n",
      "DetectorRadford & 0.92 & 0.75 & 0.17 & nan \\\\\n",
      "\\cline{1-5}\n",
      "\\end{longtable}\n",
      "\n",
      "\\begin{longtable}{lrrrr}\n",
      "\\caption{Results aggregated by explainer} \\label{resultsuserstudyexplainer} \\\\\n",
      "\\toprule\n",
      " & \\rotatebox{45}{After} & \\rotatebox{45}{Before} & \\rotatebox{45}{Increase in User Accuracy} & \\rotatebox{45}{p value} \\\\\n",
      "explainer &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\endfirsthead\n",
      "\\caption[]{Results aggregated by explainer} \\\\\n",
      "\\toprule\n",
      " & \\rotatebox{45}{After} & \\rotatebox{45}{Before} & \\rotatebox{45}{Increase in User Accuracy} & \\rotatebox{45}{p value} \\\\\n",
      "explainer &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\endhead\n",
      "\\midrule\n",
      "\\multicolumn{5}{r}{Continued on next page} \\\\\n",
      "\\midrule\n",
      "\\endfoot\n",
      "\\bottomrule\n",
      "\\endlastfoot\n",
      "SHAP\\_Explainer & 0.83 & 0.71 & 0.12 & 0.31 \\\\\n",
      "\\cline{1-5}\n",
      "\\end{longtable}\n",
      "\n",
      "\\begin{longtable}{llrrrr}\n",
      "\\caption{Results aggregated by explainer and detector pairing} \\label{resultsuserstudyexplainerdetector} \\\\\n",
      "\\toprule\n",
      " &  & \\rotatebox{45}{After} & \\rotatebox{45}{Before} & \\rotatebox{45}{Increase in User Accuracy} & \\rotatebox{45}{p value} \\\\\n",
      "explainer & detector &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\endfirsthead\n",
      "\\caption[]{Results aggregated by explainer and detector pairing} \\\\\n",
      "\\toprule\n",
      " &  & \\rotatebox{45}{After} & \\rotatebox{45}{Before} & \\rotatebox{45}{Increase in User Accuracy} & \\rotatebox{45}{p value} \\\\\n",
      "explainer & detector &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\endhead\n",
      "\\midrule\n",
      "\\multicolumn{6}{r}{Continued on next page} \\\\\n",
      "\\midrule\n",
      "\\endfoot\n",
      "\\bottomrule\n",
      "\\endlastfoot\n",
      "\\multirow[c]{2}{*}{SHAP\\_Explainer} & DetectorGuo & 0.75 & 0.67 & 0.08 & nan \\\\\n",
      "\\cline{2-6}\n",
      " & DetectorRadford & 0.92 & 0.75 & 0.17 & nan \\\\\n",
      "\\cline{1-6} \\cline{2-6}\n",
      "\\end{longtable}\n",
      "\n",
      "\\begin{longtable}{lllrr}\n",
      "\\caption{Lickert Scale Items on detector-explainer level} \\label{lickert-detector-explainer} \\\\\n",
      "\\toprule\n",
      " &  &  & \\rotatebox{45}{label} & \\rotatebox{45}{p value} \\\\\n",
      "detector & explainer & question_nr &  &  \\\\\n",
      "\\midrule\n",
      "\\endfirsthead\n",
      "\\caption[]{Lickert Scale Items on detector-explainer level} \\\\\n",
      "\\toprule\n",
      " &  &  & \\rotatebox{45}{label} & \\rotatebox{45}{p value} \\\\\n",
      "detector & explainer & question_nr &  &  \\\\\n",
      "\\midrule\n",
      "\\endhead\n",
      "\\midrule\n",
      "\\multicolumn{5}{r}{Continued on next page} \\\\\n",
      "\\midrule\n",
      "\\endfoot\n",
      "\\bottomrule\n",
      "\\endlastfoot\n",
      "\\multirow[c]{5}{*}{DetectorGuo} & \\multirow[c]{5}{*}{SHAP\\_Explainer} & 1 & 3.50 & 0.26 \\\\\n",
      "\\cline{3-5}\n",
      " &  & 2 & 3.33 & 0.44 \\\\\n",
      "\\cline{3-5}\n",
      " &  & 3 & 3.42 & 0.27 \\\\\n",
      "\\cline{3-5}\n",
      " &  & 4 & 3.25 & 0.27 \\\\\n",
      "\\cline{3-5}\n",
      " &  & 5 & \\bfseries 3.42 & 0.02 \\\\\n",
      "\\cline{1-5} \\cline{2-5} \\cline{3-5}\n",
      "\\multirow[c]{5}{*}{DetectorRadford} & \\multirow[c]{5}{*}{SHAP\\_Explainer} & 1 & 3.33 & 0.27 \\\\\n",
      "\\cline{3-5}\n",
      " &  & 2 & \\bfseries 3.58 & 0.01 \\\\\n",
      "\\cline{3-5}\n",
      " &  & 3 & 3.42 & 0.10 \\\\\n",
      "\\cline{3-5}\n",
      " &  & 4 & 3.17 & 0.44 \\\\\n",
      "\\cline{3-5}\n",
      " &  & 5 & 2.92 & 0.72 \\\\\n",
      "\\cline{1-5} \\cline{2-5} \\cline{3-5}\n",
      "\\end{longtable}\n",
      "\n",
      "\\begin{longtable}{llrr}\n",
      "\\caption{Lickert Scale Items on explainer level} \\label{lickert-explainer} \\\\\n",
      "\\toprule\n",
      " &  & \\rotatebox{45}{label} & \\rotatebox{45}{p value} \\\\\n",
      "explainer & question_nr &  &  \\\\\n",
      "\\midrule\n",
      "\\endfirsthead\n",
      "\\caption[]{Lickert Scale Items on explainer level} \\\\\n",
      "\\toprule\n",
      " &  & \\rotatebox{45}{label} & \\rotatebox{45}{p value} \\\\\n",
      "explainer & question_nr &  &  \\\\\n",
      "\\midrule\n",
      "\\endhead\n",
      "\\midrule\n",
      "\\multicolumn{4}{r}{Continued on next page} \\\\\n",
      "\\midrule\n",
      "\\endfoot\n",
      "\\bottomrule\n",
      "\\endlastfoot\n",
      "\\multirow[c]{5}{*}{SHAP\\_Explainer} & 1 & 3.42 & 0.11 \\\\\n",
      "\\cline{2-4}\n",
      " & 2 & 3.46 & 0.05 \\\\\n",
      "\\cline{2-4}\n",
      " & 3 & 3.42 & 0.06 \\\\\n",
      "\\cline{2-4}\n",
      " & 4 & 3.21 & 0.17 \\\\\n",
      "\\cline{2-4}\n",
      " & 5 & 3.17 & 0.26 \\\\\n",
      "\\cline{1-4} \\cline{2-4}\n",
      "\\end{longtable}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for  l in latex_output:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# # \"Reproducing\" information from Table 1/2 in Hase et al.:\n",
    "\n",
    "\n",
    "# user_metrics_eval = df_phase_4.groupby([\"user_id\"]).apply(lambda x : user_metrics(x,df_user_study)) # TODO\n",
    "# df_change = user_metrics_eval - user_metrics_pre\n",
    "# df_change = df_change.rename(columns={\"User Accuracy\": \"Change in User Accuracy\"})\n",
    "\n",
    "# user_acc_col = df_change[\"Change in User Accuracy\"] # for convenience\n",
    "\n",
    "# # use student t for low number of samples\n",
    "# lower, upper = stats.t.interval(\n",
    "# confidence=0.95, \n",
    "# df=len(user_acc_col)-1, # degrees of freedom = # samples - 1 for mean\n",
    "#             loc=user_acc_col.mean(), \n",
    "#             scale=stats.sem(user_acc_col)\n",
    "#             ) \n",
    "\n",
    "# p_val = ttest_ind(user_metrics_eval[\"User Accuracy\"],user_metrics_pre[\"User Accuracy\"]).pvalue\n",
    "\n",
    "# k_alpha = krippendorff.alpha(reliability_data=df_phase_4.groupby([\"user_id\"]).apply(lambda df : user_responses.astype(int).to_list()).to_list())\n",
    "\n",
    "\n",
    "\n",
    "# lower_b, upper_b = stats.bootstrap((user_acc_col,), np.mean, confidence_level=0.95,).confidence_interval\n",
    "\n",
    "# # print results\n",
    "# #  print(\"Mean change in acc\",user_acc_col.mean())\n",
    "# # print(\"CI for mean change: [{},{}]\".format(lower,upper))\n",
    "\n",
    "# ##    print(\"CI by bootstrap: [{},{}]\".format(lower_b, upper_b))\n",
    "\n",
    "\n",
    "# #  print(\"p=%.10f\" % p_val, \"significant (< 0.05)\" if p_val < 0.05 else \"NOT significant (> 0.05)\")\n",
    "# #   print(\"Krippendorff between users: {}\".format(k_alpha))\n",
    "# return p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_user_study(df_user_study, df_phase_2, df_phase_4):\n",
    "#     # \"Reproducing\" information from Table 1/2 in Hase et al.:\n",
    "#     user_metrics_pre = df_phase_2.groupby([\"user_id\"]).apply(lambda x : user_metrics(x,df_user_study))\n",
    "\n",
    "#     user_metrics_eval = df_phase_4.groupby([\"user_id\"]).apply(lambda x : user_metrics(x,df_user_study)) # TODO\n",
    "#     df_change = user_metrics_eval - user_metrics_pre\n",
    "#     df_change = df_change.rename(columns={\"User Accuracy\": \"Change in User Accuracy\"})\n",
    "\n",
    "#     user_acc_col = df_change[\"Change in User Accuracy\"] # for convenience\n",
    "\n",
    "#     # use student t for low number of samples\n",
    "#     lower, upper = stats.t.interval(\n",
    "#     confidence=0.95, \n",
    "#     df=len(user_acc_col)-1, # degrees of freedom = # samples - 1 for mean\n",
    "#               loc=user_acc_col.mean(), \n",
    "#               scale=stats.sem(user_acc_col)\n",
    "#               ) \n",
    "    \n",
    "#     p_val = ttest_ind(user_metrics_eval[\"User Accuracy\"],user_metrics_pre[\"User Accuracy\"]).pvalue\n",
    "\n",
    "#     k_alpha = krippendorff.alpha(reliability_data=df_phase_4.groupby([\"user_id\"]).apply(lambda df : user_responses.astype(int).to_list()).to_list())\n",
    "\n",
    "\n",
    "\n",
    "#     lower_b, upper_b = stats.bootstrap((user_acc_col,), np.mean, confidence_level=0.95,).confidence_interval\n",
    "    \n",
    "#     # print results\n",
    "#   #  print(\"Mean change in acc\",user_acc_col.mean())\n",
    "#    # print(\"CI for mean change: [{},{}]\".format(lower,upper))\n",
    "\n",
    "# ##    print(\"CI by bootstrap: [{},{}]\".format(lower_b, upper_b))\n",
    "\n",
    "    \n",
    "#   #  print(\"p=%.10f\" % p_val, \"significant (< 0.05)\" if p_val < 0.05 else \"NOT significant (> 0.05)\")\n",
    "#  #   print(\"Krippendorff between users: {}\".format(k_alpha))\n",
    "#     return p_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def simulate_hase(\n",
    "\n",
    "#         n_learn = 16,\n",
    "#         n_eval = 16,\n",
    "#         n_users = 10,\n",
    "\n",
    "#         mu_got_it_right_pre=0.5,\n",
    "#         sigma_got_it_right_pre=0.05,\n",
    "\n",
    "#         mu_gain = 0.1,\n",
    "#         sigma_gain = 0.1,\n",
    "\n",
    "\n",
    "# ):\n",
    "#     users = []\n",
    "#     user_dist_without = lambda : np.clip(np.random.normal(mu_got_it_right_pre, sigma_got_it_right_pre, 1)[0], 0,1)\n",
    "#     user_dist_gain = lambda : np.clip(np.random.normal(mu_gain, sigma_gain, 1)[0], -1,1)\n",
    "#     for i in range(1, n_users+1):\n",
    "#         p_without = user_dist_without()\n",
    "#         p_with = np.clip(p_without + user_dist_gain(), 0,1)\n",
    "#         users.append((\"u_%s\" % i, p_without ,p_with))\n",
    "#     documents_learn_1_2 = [\"l_%s\" % i for i in range(1,n_learn+1)]\n",
    "#     documents_pre_eval = [\"e_%s\" % i for i in range(1,n_eval+1)]\n",
    "\n",
    "#     df_detector_output = mock_detector_responses(documents_pre_eval)\n",
    "\n",
    "#     responses_pre, responses_eval = mock_user_responses(df_detector_output, documents_pre_eval, users)\n",
    "#     df_pre =pd.DataFrame(responses_pre, columns=columns_experiment)\n",
    "#     df_eval =pd.DataFrame(responses_eval, columns=columns_experiment)\n",
    "\n",
    "#  #   print(\"# responses pre\", len(responses_pre))\n",
    "#   #  print(\"# responses pre per method\", len(responses_pre)/3)\n",
    "#    # print(\"Each user saw {} instances. \".format(2*n_learn + 2*n_eval) )\n",
    "#    # print(\"Used {} unique documents. A set of {} in phase 1 and 3; and a set of {} in phase 2 and 4.\".format(n_learn + n_eval,n_learn, n_eval))\n",
    "\n",
    "# #    print(\"Results based on {} unique eval documents.\".format(n_eval))\n",
    "\n",
    "# #    print(\"Results based on {} datapoints.\".format(len(responses_eval)))\n",
    "#     p_value = evaluate_user_study(df_detector_output, df_pre, df_eval)\n",
    "#     return p_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
