{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\transformers\\generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "Exporting to onnx... |################################| 3/3\n",
      "\u001b[?25h\u001b[?25l\r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "quantize_dynamic() got an unexpected keyword argument 'activation_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[0;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt5-small\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mexport_and_get_onnx_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      8\u001b[0m t_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslate English to French: The universe is a dark forest.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\fastT5\\onnx_models.py:199\u001b[0m, in \u001b[0;36mexport_and_get_onnx_model\u001b[1;34m(model_or_model_path, quantized)\u001b[0m\n\u001b[0;32m    195\u001b[0m onnx_model_paths \u001b[38;5;241m=\u001b[39m generate_onnx_representation(model_or_model_path)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m quantized:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;66;03m# Step 2. (recommended) quantize the converted model for fast inference and to reduce model size.\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m     quant_model_paths \u001b[38;5;241m=\u001b[39m \u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_model_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# step 3. setup onnx runtime\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting up onnx model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\fastT5\\onnx_exporter.py:266\u001b[0m, in \u001b[0;36mquantize\u001b[1;34m(models_name_or_path)\u001b[0m\n\u001b[0;32m    264\u001b[0m model_name \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mas_posix()\n\u001b[0;32m    265\u001b[0m output_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-quantized.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mquantize_dynamic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_channel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivation_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mQuantType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQUInt8\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mQuantType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQUInt8\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimize_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# op_types_to_quantize=['MatMul', 'Relu', 'Add', 'Mul' ],\u001b[39;00m\n\u001b[0;32m    274\u001b[0m quant_model_paths\u001b[38;5;241m.\u001b[39mappend(output_model_name)\n\u001b[0;32m    275\u001b[0m bar\u001b[38;5;241m.\u001b[39mnext()\n",
      "\u001b[1;31mTypeError\u001b[0m: quantize_dynamic() got an unexpected keyword argument 'activation_type'"
     ]
    }
   ],
   "source": [
    "from fastT5 import export_and_get_onnx_model\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = 't5-small'\n",
    "model = export_and_get_onnx_model(model_name)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "t_input = \"translate English to French: The universe is a dark forest.\"\n",
    "token = tokenizer(t_input, return_tensors='pt')\n",
    "\n",
    "tokens = model.generate(input_ids=token['input_ids'],\n",
    "               attention_mask=token['attention_mask'],\n",
    "               num_beams=2)\n",
    "\n",
    "output = tokenizer.decode(tokens.squeeze(), skip_special_tokens=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement onnxruntime==1.10.0 (from versions: 1.15.0, 1.15.1, 1.16.0, 1.16.1, 1.16.2, 1.16.3)\n",
      "ERROR: No matching distribution found for onnxruntime==1.10.0\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install onnxruntime==1.10.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
