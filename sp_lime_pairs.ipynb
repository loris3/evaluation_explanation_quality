{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "N_DEBUG = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PHASE_1_3 = 16\n",
    "N_PHASE_2_4 = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified experiment of Hase et al. (see simulatability.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainer_wrappers import LIME_Explainer, SHAP_Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detector_guo import DetectorGuo\n",
    "from detector_dummy import DetectorDummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle(\"./dataset_test.pkl\")\n",
    "test = test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = list(test[\"answer\"])\n",
    "gold_labels = list(test[\"author\"] == \"human_answers\") # convention: 0: machine, 1: human, see detector.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = DetectGPT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = SHAP_Explainer(detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class from LIME, adapted.\n",
    "class SubmodularPick(object):\n",
    "    \"\"\"Class for submodular pick\n",
    "\n",
    "    Saves a representative sample of explanation objects using SP-LIME,\n",
    "    as well as saving all generated explanations\n",
    "\n",
    "    First, a collection of candidate explanations are generated\n",
    "    (see explain_instance). From these candidates, num_exps_desired are\n",
    "    chosen using submodular pick. (see marcotcr et al paper).\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 fi_explainer,\n",
    "                 data,\n",
    "                 predict_fn,\n",
    "                 method='sample',\n",
    "                 sample_size=1000,\n",
    "                 num_exps_desired=5,\n",
    "         \n",
    "                 **kwargs):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: a numpy array where each row is a single input into predict_fn\n",
    "            predict_fn: prediction function. For classifiers, this should be a\n",
    "                    function that takes a numpy array and outputs prediction\n",
    "                    probabilities. For regressors, this takes a numpy array and\n",
    "                    returns the predictions. For ScikitClassifiers, this is\n",
    "                    `classifier.predict_proba()`. For ScikitRegressors, this\n",
    "                    is `regressor.predict()`. The prediction function needs to work\n",
    "                    on multiple feature vectors (the vectors randomly perturbed\n",
    "                    from the data_row).\n",
    "            method: The method to use to generate candidate explanations\n",
    "                    method == 'sample' will sample the data uniformly at\n",
    "                    random. The sample size is given by sample_size. Otherwise\n",
    "                    if method == 'full' then explanations will be generated for the\n",
    "                    entire data. l\n",
    "            sample_size: The number of instances to explain if method == 'sample'\n",
    "            num_exps_desired: The number of explanation objects returned\n",
    "            num_features: maximum number of features present in explanation\n",
    "\n",
    "\n",
    "        Sets value:\n",
    "            sp_explanations: A list of explanation objects that has a high coverage\n",
    "            explanations: All the candidate explanations saved for potential future use.\n",
    "              \"\"\"\n",
    "\n",
    "        top_labels = kwargs.get('top_labels', 1)\n",
    "        if 'top_labels' in kwargs:\n",
    "            del kwargs['top_labels']\n",
    "        # Parse args\n",
    "        if method == 'sample':\n",
    "            if sample_size > len(data):\n",
    "                warnings.warn(\"\"\"Requested sample size larger than\n",
    "                              size of input data. Using all data\"\"\")\n",
    "                sample_size = len(data)\n",
    "            all_indices = np.arange(len(data))\n",
    "            np.random.seed(2202)\n",
    "            np.random.shuffle(all_indices)\n",
    "            sample_indices = all_indices[:sample_size]\n",
    "        elif method == 'full':\n",
    "            sample_indices = np.arange(len(data))\n",
    "        else:\n",
    "            raise ValueError('Method must be \\'sample\\' or \\'full\\'')\n",
    "\n",
    "        # Generate Explanations\n",
    "        self.explanations = []\n",
    "        for i in sample_indices:\n",
    "           # explainer.delete_cached_explanation(data[i])\n",
    "            self.explanations.append(\n",
    "                explainer.get_explanation_cached(\n",
    "                    data[i]))\n",
    "        # Error handling\n",
    "        try:\n",
    "            num_exps_desired = int(num_exps_desired)\n",
    "        except TypeError:\n",
    "            return(\"Requested number of explanations should be an integer\")\n",
    "        if num_exps_desired > len(self.explanations):\n",
    "            warnings.warn(\"\"\"Requested number of explanations larger than\n",
    "                           total number of explanations, returning all\n",
    "                           explanations instead.\"\"\")\n",
    "        num_exps_desired = min(num_exps_desired, len(self.explanations))\n",
    "\n",
    "        # Find all the explanation model features used. Defines the dimension d'\n",
    "        features_dict = {}\n",
    "        feature_iter = 0\n",
    "        for exp in self.explanations:\n",
    "            labels = [0] #exp.available_labels() if exp.mode == 'classification' else [1]\n",
    "            for label in labels:\n",
    "                for feature, _ in explainer.as_list(exp, label=label):\n",
    "                    if feature not in features_dict.keys():\n",
    "                        features_dict[feature] = (feature_iter)\n",
    "                        feature_iter += 1\n",
    "        d_prime = len(features_dict.keys())\n",
    "\n",
    "        # Create the n x d' dimensional 'explanation matrix', W\n",
    "        # loris: note that this is BOW now\n",
    "        W = np.zeros((len(self.explanations), d_prime))\n",
    "        for i, exp in enumerate(self.explanations):\n",
    "            labels = [0]# if exp.mode == 'classification' else [1]\n",
    "            for label in labels:\n",
    "                for feature, value in explainer.as_list(exp, label=label):\n",
    "                    # loris: TODO BOW! this sums FI scores for the same word in different contexts! \n",
    "                    W[i, features_dict[feature]] += value\n",
    "     #   print(\"W\", W)\n",
    "    #    print(\"w.shape\", W.shape)\n",
    "        self.W = W\n",
    "        self.sample_indices = sample_indices\n",
    "        self.features_dict = features_dict\n",
    "        return \n",
    "        # Create the global importance vector, I_j described in the paper\n",
    "        importance = np.sum(abs(W), axis=0)**.5\n",
    "\n",
    "        # Now run the SP-LIME greedy algorithm\n",
    "        remaining_indices = set(range(len(self.explanations)))\n",
    "        V = []\n",
    "        for _ in range(num_exps_desired):\n",
    "            best = 0\n",
    "            best_ind = None\n",
    "            current = 0\n",
    "            for i in remaining_indices:\n",
    "                current = np.dot(\n",
    "                        (np.sum(abs(W)[V + [i]], axis=0) > 0), importance\n",
    "                        )  # coverage function\n",
    "                if current >= best:\n",
    "                    best = current\n",
    "                    best_ind = i\n",
    "            V.append(best_ind)\n",
    "            remaining_indices -= {best_ind}\n",
    "\n",
    "        self.sp_explanations = [self.explanations[i] for i in V]\n",
    "        self.V = V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_obj = SubmodularPick(explainer.explainer, documents, explainer.detector.predict_proba, sample_size=10, num_exps_desired=5, method=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = sp_obj.sample_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(sp_obj.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_obj.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1,2,3,4,5],[1,2,3,4,5]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "sim = cosine_similarity(normalize(sp_obj.W, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(np.diag(sim), np.ones_like(np.diag(sim))), \"FI scores to small!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(np.triu(sim), np.rot90(np.fliplr(np.tril(sim))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([-4.01154804e-18,  3.29326410e-18,  2.92734587e-18,\n",
    "         1.01915004e-17,  2.00577402e-18,  2.16840434e-19,\n",
    "        -3.79470760e-18, -2.54787511e-18, -6.66784336e-18,\n",
    "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
    "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
    "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
    "         0.00000000e+00])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(cosine_similarity(a.reshape(1, -1),Y=a.T.reshape(1, -1))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_pairs = []\n",
    "# sim_ = np.copy(sim)\n",
    "# sim_ = np.triu(sim_,k=1)\n",
    "# print(sim_)\n",
    "# for i in range(0,10):\n",
    "#     idx_max = np.unravel_index(sim_.argmax(), sim_.shape)\n",
    "#     idx_pairs.append([sample_indices[ii] for ii in idx_max])\n",
    "#     sim_[idx_max] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_pairs = []\n",
    "features = []\n",
    "W_ = np.copy(sp_obj.W)\n",
    "\n",
    "features_dict = sp_obj.features_dict.copy()\n",
    "\n",
    "\n",
    "for i in range(len(sp_obj.sample_indices)):\n",
    "    sim = cosine_similarity(normalize(W_, axis=0))\n",
    "    sim = np.triu(sim,k=1)\n",
    "\n",
    "    idx_max = np.unravel_index(sim.argmax(), sim.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    idx_fi_non_zero_in_both = np.intersect1d(W_[idx_max[0]].nonzero(),W_[idx_max[1]].nonzero())\n",
    "    \n",
    "   # print(\"idx_fi_non_zero_in_both\",idx_fi_non_zero_in_both)\n",
    "\n",
    "    features_pair = []\n",
    "    for iii in idx_fi_non_zero_in_both:\n",
    "        key = list(features_dict.keys())[list(features_dict.values()).index(iii)]\n",
    "        features_pair.append(key)\n",
    "        del features_dict[key]\n",
    "        features_dict = {key:i for i, key in enumerate(features_dict.keys())}\n",
    "\n",
    "    if len(features_pair) > 0 and gold_labels[sample_indices[idx_max[0]]] and gold_labels[sample_indices[idx_max[0]]]:\n",
    "        a,b = detector.predict_label([documents[sample_indices[idx_max[0]]], documents[sample_indices[idx_max[1]]]])\n",
    "        if a == b:\n",
    "            idx_pairs.append([sample_indices[ii] for ii in idx_max])\n",
    "            features.append(features_pair)\n",
    "    W_ = np.delete(W_, idx_fi_non_zero_in_both, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a==b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_phase_3 = \"\"\"\n",
    "<p><b>This is a {kind_of_document} document.</b></p>\n",
    "<p>The detector {correctly_or_wrongly} predicted that this document was... </p>\n",
    "<p>&emsp; ... machine generated with {p_machine} % confidence.</p>\n",
    "<p>&emsp; ... human written with {p_human} % confidence.</p> \n",
    "<div style=\"float:left; height:30em;\">{barplot_machine}{barplot_human}</div>\n",
    "\n",
    "\n",
    "<div style=\"float:left;\">{highlighted_text}</div>\n",
    "\"\"\"\n",
    "def printt(document, gold_label):\n",
    "    p_machine, p_human = detector.predict_proba([document])[0]\n",
    "    machine, human = explainer.get_barplots_HTML(document)\n",
    "    display(HTML(prompt_template_phase_3.format(\n",
    "    p_machine=int(p_machine*100), \n",
    "    p_human=int(p_human*100),\n",
    "    barplot_machine=machine,\n",
    "    barplot_human=human,\n",
    "    kind_of_document= \"machine generated\" if gold_label == False else \"human written\", \n",
    "    correctly_or_wrongly= \"correctly\" if detector.predict_label([document])[0] == gold_label else \"wrongly\", \n",
    "    highlighted_text=explainer.get_highlighted_text_HTML(document),\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(explainer.get_highlighted_text_HTML(\"Test !\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (a,b), features in zip(idx_pairs, features):\n",
    "    print(a,b, features)\n",
    "    printt(documents[a], gold_labels[a])\n",
    "    printt(documents[b], gold_labels[b])\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
