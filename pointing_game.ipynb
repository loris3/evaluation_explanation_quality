{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "N_DEBUG = 50\n",
    "N_RANDOM_RUNS = 100\n",
    "OUTPUT_DIR = \"./pointing_game_datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detector_radford import DetectorRadford\n",
    "from detector_detectgpt import DetectorDetectGPT\n",
    "from detector_guo import DetectorGuo\n",
    "detector_classes = [DetectorGuo, DetectorRadford,DetectorDetectGPT]\n",
    "\n",
    "from explainer_wrappers import LIME_Explainer, SHAP_Explainer, Anchor_Explainer, Random_Explainer\n",
    "explainer_classes =  [Random_Explainer] * N_RANDOM_RUNS +[LIME_Explainer, SHAP_Explainer, Anchor_Explainer ]\n",
    "explainer_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pointing_game_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle(\"./dataset_test.pkl\")\n",
    "test = test # always load the full dataset! (np.random.shuffle(tokenized_sentences)). slice the actual hybrid_documents if debugging!\n",
    "documents = test[\"answer\"]\n",
    "gold_labels = test[\"author\"] == \"human_answers\" # convention: 0: machine, 1: human, see detector.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series((len(list(nlp(d).sents)) for d in documents)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep a copy of the hybrid documents for the assert in the loop\n",
    "ref_assert_hybrid_documents, _, _ = pointing_game_util.hybrid(documents.to_list(), gold_labels.to_list(), word_tokenizer=LIME_Explainer(DetectorRadford()).tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series((len(list(nlp(d).sents)) for d in ref_assert_hybrid_documents)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 6181.41it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 6823.36it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7847.61it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7481.45it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8061.85it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7091.56it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8312.72it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8189.34it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8446.02it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8718.16it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8443.76it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7931.45it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8436.11it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 5990.76it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8186.34it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7930.57it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7826.59it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8448.97it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8192.94it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 5238.89it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8182.92it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7867.01it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 6664.61it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8433.98it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7950.04it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8172.27it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8445.70it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8588.85it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8446.83it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8311.57it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8447.65it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 5860.56it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7720.75it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8361.76it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 4450.53it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7935.38it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 6996.57it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7598.12it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8044.16it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8184.74it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8186.10it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8438.37it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8443.19it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8304.22it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8437.30it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7604.58it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7605.49it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8168.28it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7944.98it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 6202.59it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7607.79it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8190.70it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8053.05it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8054.20it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 6278.17it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7505.06it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7303.53it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7504.47it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8142.70it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8186.57it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7888.08it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8187.69it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7714.46it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8444.82it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 6635.32it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 4488.19it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7943.48it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8447.65it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8445.20it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8446.83it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8579.06it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8045.64it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8312.17it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8142.94it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7934.61it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8189.46it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8577.05it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8314.54it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 1298.71it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8039.55it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7937.27it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8062.54it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7937.93it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8444.32it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8447.08it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 3850.38it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7105.12it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8193.12it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 5133.76it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7941.20it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8190.82it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7942.98it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 6274.15it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7400.01it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8287.93it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 6424.80it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 6585.19it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7704.11it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 7713.31it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 8063.39it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 1163.45it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 2421.24it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for detector_class in detector_classes:  \n",
    "    detector = detector_class()\n",
    "    predictions_hybrid = None\n",
    "    for i, explainer_class in enumerate(explainer_classes):\n",
    "        if explainer_class == Random_Explainer:\n",
    "            explainer = explainer_class(detector,seed=i)\n",
    "        else:\n",
    "            explainer = explainer_class(detector)\n",
    "        if explainer_class == Anchor_Explainer and detector_class == DetectorDetectGPT:\n",
    "            continue\n",
    "\n",
    "        hybrid_documents, tokenized_hybrid_documents, GT = pointing_game_util.hybrid(documents.to_list(), gold_labels.to_list(), word_tokenizer=explainer.tokenize)\n",
    "        assert (all([a==b for a,b in zip(ref_assert_hybrid_documents,hybrid_documents)])), \"(full) Hybrid documents don't match\" # tokenized_hybrid_documents differ by design to make the calculation of the pointing game accuracy easier\n",
    "        \n",
    "        # write csv (for debug purposes)\n",
    "        pd.DataFrame(zip(hybrid_documents, tokenized_hybrid_documents, GT), columns=[\"Hybrid Document\", \"Tokenized Hybrid Document\", \"GT\"]).to_csv(os.path.join(OUTPUT_DIR, detector.__class__.__name__+ \"-\"+explainer.__class__.__name__+\".csv\"),index=False)\n",
    "        if predictions_hybrid is None:\n",
    "            predictions_hybrid = detector.predict_label(hybrid_documents) # the assert above guarantees that the documents are the same across explainers\n",
    "\n",
    "        pointing_game_scores = pointing_game_util.get_pointing_game_scores(hybrid_documents, explainer, predictions_hybrid, GT)\n",
    "        results.extend([(explainer.__class__.__name__, detector.__class__.__name__, pointing_game_score) for pointing_game_score in pointing_game_scores])\n",
    "    \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some formatting functions\n",
    "def get_p_asterisks(group):\n",
    "    val =  group.mean()\n",
    "   # print(group.name)\n",
    "    _, p = ttest_1samp(group, popmean=0.5)\n",
    "    if p <= 0.001:\n",
    "        return \"{:.2f}\\\\textsuperscript{{***}}\".format(val)\n",
    "    if p <= 0.01:\n",
    "        return \"{:.2f}\\\\textsuperscript{{**}}\".format(val)\n",
    "    if p <= 0.05:\n",
    "        return \"{:.2f}\\\\textsuperscript{{*}}\".format(val)\n",
    "    if p > 0.05:\n",
    "        return \"{:.2f}\\\\textsuperscript{{ns}}\".format(val)\n",
    "\n",
    "def highlight_max(col):\n",
    "    vals = col.str.extract(r\"(-*\\d*\\.\\d*)\").astype(float).values.flatten()\n",
    "    max_val = vals.max()\n",
    "    return [\"font-weight: bold;\" if c == max_val else \"\" for c in vals ]\n",
    "def df_to_latex(styled_df, caption=\"TODO\", label=\"TODO\"):\n",
    "    return styled_df.to_latex(environment=\"table\", convert_css=True, clines=\"all;data\", hrules=True, caption=caption, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_dff(dff, groupby):\n",
    "    dff[\"Explainer\"] = dff[\"Explainer\"].str.replace(\"_Explainer\", \"\")\n",
    "    p_results = dff.groupby(groupby).agg(\n",
    "    {\n",
    "          \"Pointing Game Scores\": get_p_asterisks,\n",
    "        }\n",
    "    )\n",
    "    p_results = p_results.style.apply(highlight_max, subset=p_results.columns)\n",
    "    return p_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Explainer</th>\n",
       "      <th>Detector</th>\n",
       "      <th>Pointing Game Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random_Explainer</td>\n",
       "      <td>DetectorGuo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random_Explainer</td>\n",
       "      <td>DetectorGuo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random_Explainer</td>\n",
       "      <td>DetectorGuo</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random_Explainer</td>\n",
       "      <td>DetectorGuo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random_Explainer</td>\n",
       "      <td>DetectorGuo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83463</th>\n",
       "      <td>SHAP_Explainer</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83464</th>\n",
       "      <td>SHAP_Explainer</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83465</th>\n",
       "      <td>SHAP_Explainer</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83466</th>\n",
       "      <td>SHAP_Explainer</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83467</th>\n",
       "      <td>SHAP_Explainer</td>\n",
       "      <td>DetectorDetectGPT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83468 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Explainer           Detector  Pointing Game Scores\n",
       "0      Random_Explainer        DetectorGuo                   0.0\n",
       "1      Random_Explainer        DetectorGuo                   0.0\n",
       "2      Random_Explainer        DetectorGuo                   1.0\n",
       "3      Random_Explainer        DetectorGuo                   0.0\n",
       "4      Random_Explainer        DetectorGuo                   0.0\n",
       "...                 ...                ...                   ...\n",
       "83463    SHAP_Explainer  DetectorDetectGPT                   0.0\n",
       "83464    SHAP_Explainer  DetectorDetectGPT                   0.0\n",
       "83465    SHAP_Explainer  DetectorDetectGPT                   0.0\n",
       "83466    SHAP_Explainer  DetectorDetectGPT                   0.0\n",
       "83467    SHAP_Explainer  DetectorDetectGPT                   0.0\n",
       "\n",
       "[83468 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = pd.DataFrame(results, columns=[\"Explainer\", \"Detector\", \"Pointing Game Scores\"])\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c729b_row3_col0 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c729b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c729b_level0_col0\" class=\"col_heading level0 col0\" >Pointing Game Scores</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Explainer</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c729b_level0_row0\" class=\"row_heading level0 row0\" >Anchor</th>\n",
       "      <td id=\"T_c729b_row0_col0\" class=\"data row0 col0\" >0.59\\textsuperscript{***}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c729b_level0_row1\" class=\"row_heading level0 row1\" >LIME</th>\n",
       "      <td id=\"T_c729b_row1_col0\" class=\"data row1 col0\" >0.55\\textsuperscript{**}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c729b_level0_row2\" class=\"row_heading level0 row2\" >Random</th>\n",
       "      <td id=\"T_c729b_row2_col0\" class=\"data row2 col0\" >0.57\\textsuperscript{***}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c729b_level0_row3\" class=\"row_heading level0 row3\" >SHAP</th>\n",
       "      <td id=\"T_c729b_row3_col0\" class=\"data row3 col0\" >0.69\\textsuperscript{***}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x256e93a2590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_results_aggregate_level = style_dff(dff, groupby=[\"Explainer\"])\n",
    "display(p_results_aggregate_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fb0cb_row9_col0 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fb0cb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fb0cb_level0_col0\" class=\"col_heading level0 col0\" >Pointing Game Scores</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Explainer</th>\n",
       "      <th class=\"index_name level1\" >Detector</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fb0cb_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"2\">Anchor</th>\n",
       "      <th id=\"T_fb0cb_level1_row0\" class=\"row_heading level1 row0\" >DetectorGuo</th>\n",
       "      <td id=\"T_fb0cb_row0_col0\" class=\"data row0 col0\" >0.68\\textsuperscript{***}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb0cb_level1_row1\" class=\"row_heading level1 row1\" >DetectorRadford</th>\n",
       "      <td id=\"T_fb0cb_row1_col0\" class=\"data row1 col0\" >0.49\\textsuperscript{ns}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb0cb_level0_row2\" class=\"row_heading level0 row2\" rowspan=\"3\">LIME</th>\n",
       "      <th id=\"T_fb0cb_level1_row2\" class=\"row_heading level1 row2\" >DetectorDetectGPT</th>\n",
       "      <td id=\"T_fb0cb_row2_col0\" class=\"data row2 col0\" >0.63\\textsuperscript{***}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb0cb_level1_row3\" class=\"row_heading level1 row3\" >DetectorGuo</th>\n",
       "      <td id=\"T_fb0cb_row3_col0\" class=\"data row3 col0\" >0.61\\textsuperscript{***}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb0cb_level1_row4\" class=\"row_heading level1 row4\" >DetectorRadford</th>\n",
       "      <td id=\"T_fb0cb_row4_col0\" class=\"data row4 col0\" >0.40\\textsuperscript{**}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb0cb_level0_row5\" class=\"row_heading level0 row5\" rowspan=\"3\">Random</th>\n",
       "      <th id=\"T_fb0cb_level1_row5\" class=\"row_heading level1 row5\" >DetectorDetectGPT</th>\n",
       "      <td id=\"T_fb0cb_row5_col0\" class=\"data row5 col0\" >0.58\\textsuperscript{***}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb0cb_level1_row6\" class=\"row_heading level1 row6\" >DetectorGuo</th>\n",
       "      <td id=\"T_fb0cb_row6_col0\" class=\"data row6 col0\" >0.64\\textsuperscript{***}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb0cb_level1_row7\" class=\"row_heading level1 row7\" >DetectorRadford</th>\n",
       "      <td id=\"T_fb0cb_row7_col0\" class=\"data row7 col0\" >0.48\\textsuperscript{***}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb0cb_level0_row8\" class=\"row_heading level0 row8\" rowspan=\"3\">SHAP</th>\n",
       "      <th id=\"T_fb0cb_level1_row8\" class=\"row_heading level1 row8\" >DetectorDetectGPT</th>\n",
       "      <td id=\"T_fb0cb_row8_col0\" class=\"data row8 col0\" >0.63\\textsuperscript{***}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb0cb_level1_row9\" class=\"row_heading level1 row9\" >DetectorGuo</th>\n",
       "      <td id=\"T_fb0cb_row9_col0\" class=\"data row9 col0\" >0.81\\textsuperscript{***}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb0cb_level1_row10\" class=\"row_heading level1 row10\" >DetectorRadford</th>\n",
       "      <td id=\"T_fb0cb_row10_col0\" class=\"data row10 col0\" >0.63\\textsuperscript{***}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x256b0139110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_results = style_dff(dff, groupby=[\"Explainer\", \"Detector\"])\n",
    "display(p_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = df_to_latex(p_results, label=\"pointing-game-explainer-detector\", caption=\"Scores per detector and explainer\")\n",
    "out += (df_to_latex(p_results_aggregate_level, label=\"pointing-game-explainer\", caption=\"Scores per explainer\"))\n",
    "with open(\"figures/tables_pointing_game.tex\", \"w\", encoding=\"UTF-8\") as text_file:\n",
    "    text_file.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for hybrid_document in hybrid_documents:\n",
    "\n",
    "#     explainer = LIME_Explainer(detector)\n",
    "#     explainer.get_explanation_cached(hybrid_document).show_in_notebook()\n",
    "\n",
    "#     explainer = SHAP_Explainer(detector)\n",
    "#     shap.text_plot(explainer.get_explanation_cached(hybrid_document))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using <function <lambda> at 0x00000256EC2C3560> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70.63468634686348"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "pd.read_csv(\"pointing_game_datasets/DetectorDetectGPT-Random_Explainer.csv\")[\"GT\"].agg(lambda x: x.count(\"False\")).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using <function <lambda> at 0x00000256EBCBFEC0> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52.67158671586716"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"pointing_game_datasets/DetectorDetectGPT-Random_Explainer.csv\")[\"GT\"].agg(lambda x: x.count(\"True\")).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
