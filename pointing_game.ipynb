{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "N_DEBUG = 50\n",
    "N_RANDOM_RUNS = 100\n",
    "OUTPUT_DIR = \"./pointing_game_datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detector_radford import DetectorRadford\n",
    "from detector_detectgpt import DetectorDetectGPT\n",
    "from detector_guo import DetectorGuo\n",
    "detector_classes = [DetectorGuo, DetectorRadford,DetectorDetectGPT]\n",
    "\n",
    "from explainer_wrappers import LIME_Explainer, SHAP_Explainer, Anchor_Explainer, Random_Explainer\n",
    "explainer_classes =  [LIME_Explainer, SHAP_Explainer, Anchor_Explainer ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pointing_game_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x1ab82819890>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle(\"./dataset_test.pkl\")\n",
    "test = test # always load the full dataset! (np.random.shuffle(tokenized_sentences)). slice the actual hybrid_documents if debugging!\n",
    "documents = test[\"answer\"]\n",
    "gold_labels = test[\"author\"] == \"human_answers\" # convention: 0: machine, 1: human, see detector.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series((len(list(nlp(d).sents)) for d in documents)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep a copy of the hybrid documents for the assert in the loop\n",
    "ref_assert_hybrid_documents, _, _ = pointing_game_util.hybrid(documents.to_list(), gold_labels.to_list(), word_tokenizer=LIME_Explainer(DetectorRadford()).tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series((len(list(nlp(d).sents)) for d in ref_assert_hybrid_documents)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 1138.47it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 2452.13it/s]\n",
      "100%|██████████| 271/271 [00:06<00:00, 41.27it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 1099.06it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 2044.79it/s]\n",
      "100%|██████████| 271/271 [00:06<00:00, 42.19it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 1072.93it/s]\n",
      "Generating explanations: 100%|██████████| 271/271 [00:00<00:00, 2176.28it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for detector_class in detector_classes:  \n",
    "    detector = detector_class()\n",
    "    predictions_hybrid = None\n",
    "    for i, explainer_class in enumerate(explainer_classes):\n",
    "        if explainer_class == Anchor_Explainer and detector_class == DetectorDetectGPT:\n",
    "            continue\n",
    "        explainer = explainer_class(detector)\n",
    "        hybrid_documents, tokenized_hybrid_documents, GT = pointing_game_util.hybrid(documents.to_list(), gold_labels.to_list(), word_tokenizer=explainer.tokenize)\n",
    "        assert (all([a==b for a,b in zip(ref_assert_hybrid_documents,hybrid_documents)])), \"(full) Hybrid documents don't match\" # tokenized_hybrid_documents differ by design to make the calculation of the pointing game accuracy easier\n",
    "        \n",
    "        # write csv (for debug purposes)\n",
    "        pd.DataFrame(zip(hybrid_documents, tokenized_hybrid_documents, GT), columns=[\"Hybrid Document\", \"Tokenized Hybrid Document\", \"GT\"]).to_csv(os.path.join(OUTPUT_DIR, detector.__class__.__name__+ \"-\"+explainer.__class__.__name__+\".csv\"),index=False)\n",
    "        if predictions_hybrid is None:\n",
    "            predictions_hybrid = detector.predict_label(hybrid_documents) # the assert above guarantees that the documents are the same across explainers\n",
    "\n",
    "        pointing_game_scores = pointing_game_util.get_pointing_game_scores(hybrid_documents, explainer, predictions_hybrid, GT)\n",
    "        results.extend([(doc_nr, explainer.__class__.__name__, detector.__class__.__name__, pointing_game_score) for doc_nr, pointing_game_score in enumerate(pointing_game_scores)])\n",
    "    \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "results_random = []\n",
    "for detector_class in detector_classes:  \n",
    "    detector = detector_class()\n",
    "    predictions_hybrid = None\n",
    "    for i in range(0, N_RANDOM_RUNS):\n",
    "            explainer = Random_Explainer(detector,seed=i)\n",
    "            \n",
    "            hybrid_documents, tokenized_hybrid_documents, GT = pointing_game_util.hybrid(documents.to_list(), gold_labels.to_list(), word_tokenizer=explainer.tokenize)\n",
    "            assert (all([a==b for a,b in zip(ref_assert_hybrid_documents,hybrid_documents)])), \"(full) Hybrid documents don't match\" # tokenized_hybrid_documents differ by design to make the calculation of the pointing game accuracy easier\n",
    "            if predictions_hybrid is None:\n",
    "                predictions_hybrid = detector.predict_label(hybrid_documents) # the assert above guarantees that the documents are the same across explainers\n",
    "\n",
    "            pointing_game_scores = pointing_game_util.get_pointing_game_scores(hybrid_documents, explainer, predictions_hybrid, GT)\n",
    "            results_random.extend([(doc_nr, explainer.__class__.__name__, detector.__class__.__name__, pointing_game_score, i) for doc_nr, pointing_game_score in enumerate(pointing_game_scores)])\n",
    "        \n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"doc_nr\",\"Explainer\", \"Detector\", \"Pointing Game Scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.DataFrame(results, columns=columns)\n",
    "dff_random = pd.DataFrame(results_random, columns=columns +[\"run\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import ttest_ind\n",
    "from scipy.stats import combine_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, df_random in dff_random.groupby(\"run\"):\n",
    "#     display(df_random)\n",
    "#     print([ttest_ind(df_random[\"Pointing Game Scores\"], df[\"Pointing Game Scores\"])[1] for explainer, df in dff.groupby(\"Explainer\")])\n",
    "#     print(combine_pvalues([ttest_ind(df_random[\"Pointing Game Scores\"], df[\"Pointing Game Scores\"])[1] for explainer, df in dff.groupby(\"Explainer\")]))\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_output = []\n",
    "from scipy.stats import binomtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_eec14_level0_col0, #T_eec14_level0_col1 {\n",
       "  rotatebox: {45}--rwrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_eec14\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_eec14_level0_col0\" class=\"col_heading level0 col0\" >Pointing Game Scores</th>\n",
       "      <th id=\"T_eec14_level0_col1\" class=\"col_heading level0 col1\" >p-value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Explainer</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_eec14_level0_row0\" class=\"row_heading level0 row0\" >LIME\\_Explainer</th>\n",
       "      <td id=\"T_eec14_row0_col0\" class=\"data row0 col0\" >0.546</td>\n",
       "      <td id=\"T_eec14_row0_col1\" class=\"data row0 col1\" >0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eec14_level0_row1\" class=\"row_heading level0 row1\" >Random\\_Explainer</th>\n",
       "      <td id=\"T_eec14_row1_col0\" class=\"data row1 col0\" >0.565</td>\n",
       "      <td id=\"T_eec14_row1_col1\" class=\"data row1 col1\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eec14_level0_row2\" class=\"row_heading level0 row2\" >Anchor\\_Explainer</th>\n",
       "      <td id=\"T_eec14_row2_col0\" class=\"data row2 col0\" >0.586</td>\n",
       "      <td id=\"T_eec14_row2_col1\" class=\"data row2 col1\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eec14_level0_row3\" class=\"row_heading level0 row3\" >SHAP\\_Explainer</th>\n",
       "      <td id=\"T_eec14_row3_col0\" class=\"data row3 col0\" >0.692</td>\n",
       "      <td id=\"T_eec14_row3_col1\" class=\"data row3 col1\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ac6494d5d0>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupby = [\"Explainer\"]\n",
    "label = \"results_pointing_game_explainers\"\n",
    "caption = \"Results aggregated by explainer. P-values from a binominal tests with $H_0$: No difference between this method and the next best in this list.\"\n",
    "df_random = dff_random.groupby(groupby + [\"doc_nr\"])[\"Pointing Game Scores\"].mean()\n",
    "\n",
    "df_aggregate_results = pd.DataFrame([dff.groupby(groupby)[\"Pointing Game Scores\"].mean()]).T\n",
    "df_aggregate_results = df_aggregate_results.reindex(sorted(df_aggregate_results.columns), axis=1)\n",
    "\n",
    "\n",
    "df_random_row = pd.DataFrame(df_random.groupby(groupby).mean())\n",
    "df_aggregate_results_ = pd.concat([df_aggregate_results, df_random_row])\n",
    "\n",
    "\n",
    "df_aggregate_results_.sort_values(by=\"Pointing Game Scores\", inplace=True, ascending=True)\n",
    "\n",
    "p_values = []\n",
    "itr = df_aggregate_results_.iterrows()\n",
    "next(itr)\n",
    "counts =  pd.concat([dff, dff_random]).groupby(groupby).count()\n",
    "counts = counts.reset_index()\n",
    "\n",
    "for (name_current, p_current), (name_next, p_next) in zip(df_aggregate_results_.iterrows(), itr):\n",
    "    n=counts[(counts[groupby] == name_current).all(axis=1)].iloc[0][\"Pointing Game Scores\"]\n",
    "    name_current = name_current if len(groupby) >= 2 else [name_current]\n",
    "    p_values.append((*name_current, binomtest(int(p_current.values[0] * n), n=n, p=p_next.values[0], alternative=\"less\").pvalue))\n",
    "\n",
    "result = df_aggregate_results_.join(pd.DataFrame(p_values, columns=[*groupby, \"p-value\"]).set_index(groupby)).fillna(\"\").style\\\n",
    "    .map_index(lambda v: \"rotatebox:{45}--rwrap;\", level=0, axis=1).format(precision=3).format_index(escape=\"latex\", axis=0)\n",
    "latex_output.append(result.to_latex(environment=\"table\", \n",
    "                                    convert_css=True, \n",
    "                                    clines=\"all;data\", \n",
    "                                    hrules=True, \n",
    "                                    caption=caption, \n",
    "                                    label=label)\n",
    "                                    )\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby = [\"Detector\"]\n",
    "# label = \"results_pointing_game_detector\"\n",
    "# caption = \"Results aggregated by detector (no random explanations).\"\n",
    "\n",
    "\n",
    "# df_aggregate_results = pd.DataFrame([dff.groupby(groupby)[\"Pointing Game Scores\"].mean()]).T\n",
    "# df_aggregate_results = df_aggregate_results.reindex(sorted(df_aggregate_results.columns), axis=1)\n",
    "\n",
    "# df_aggregate_results_ = df_aggregate_results \n",
    "\n",
    "\n",
    "# df_aggregate_results_.sort_values(by=\"Pointing Game Scores\", inplace=True, ascending=True)\n",
    "\n",
    "# p_values = []\n",
    "# itr = df_aggregate_results_.iterrows()\n",
    "# next(itr)\n",
    "# counts =  dff.groupby(groupby).count()\n",
    "# counts = counts.reset_index()\n",
    "\n",
    "# for (name_current, p_current), (name_next, p_next) in zip(df_aggregate_results_.iterrows(), itr):\n",
    "#     n=counts[(counts[groupby] == name_current).all(axis=1)].iloc[0][\"Pointing Game Scores\"]\n",
    "#     name_current = name_current if len(groupby) >= 2 else [name_current]\n",
    "#     p_values.append((*name_current, binomtest(int(p_current.values[0] * n), n=n, p=p_next.values[0], alternative=\"less\").pvalue))\n",
    "\n",
    "# result = df_aggregate_results_.join(pd.DataFrame(p_values, columns=[*groupby, \"p-value\"]).set_index(groupby)).fillna(\"\").style\\\n",
    "#     .map_index(lambda v: \"rotatebox:{45}--rwrap;\", level=0, axis=1).format(precision=3).format_index(escape=\"latex\", axis=0)\n",
    "# latex_output.append(result.to_latex(environment=\"table\", \n",
    "#                                     convert_css=True, \n",
    "#                                     clines=\"all;data\", \n",
    "#                                     hrules=True, \n",
    "#                                     caption=caption, \n",
    "#                                     label=label))\n",
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per group but seperate tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a2fb6_level0_col0, #T_a2fb6_level0_col1 {\n",
       "  rotatebox: {45}--rwrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a2fb6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a2fb6_level0_col0\" class=\"col_heading level0 col0\" >Pointing Game Scores</th>\n",
       "      <th id=\"T_a2fb6_level0_col1\" class=\"col_heading level0 col1\" >p-value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Explainer</th>\n",
       "      <th class=\"index_name level1\" >Detector</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a2fb6_level0_row0\" class=\"row_heading level0 row0\" >LIME\\_Explainer</th>\n",
       "      <th id=\"T_a2fb6_level1_row0\" class=\"row_heading level1 row0\" >DetectorGuo</th>\n",
       "      <td id=\"T_a2fb6_row0_col0\" class=\"data row0 col0\" >0.605</td>\n",
       "      <td id=\"T_a2fb6_row0_col1\" class=\"data row0 col1\" >0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2fb6_level0_row1\" class=\"row_heading level0 row1\" >Random\\_Explainer</th>\n",
       "      <th id=\"T_a2fb6_level1_row1\" class=\"row_heading level1 row1\" >DetectorGuo</th>\n",
       "      <td id=\"T_a2fb6_row1_col0\" class=\"data row1 col0\" >0.635</td>\n",
       "      <td id=\"T_a2fb6_row1_col1\" class=\"data row1 col1\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2fb6_level0_row2\" class=\"row_heading level0 row2\" >Anchor\\_Explainer</th>\n",
       "      <th id=\"T_a2fb6_level1_row2\" class=\"row_heading level1 row2\" >DetectorGuo</th>\n",
       "      <td id=\"T_a2fb6_row2_col0\" class=\"data row2 col0\" >0.681</td>\n",
       "      <td id=\"T_a2fb6_row2_col1\" class=\"data row2 col1\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2fb6_level0_row3\" class=\"row_heading level0 row3\" >SHAP\\_Explainer</th>\n",
       "      <th id=\"T_a2fb6_level1_row3\" class=\"row_heading level1 row3\" >DetectorGuo</th>\n",
       "      <td id=\"T_a2fb6_row3_col0\" class=\"data row3 col0\" >0.812</td>\n",
       "      <td id=\"T_a2fb6_row3_col1\" class=\"data row3 col1\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ac64990590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_34c49_level0_col0, #T_34c49_level0_col1 {\n",
       "  rotatebox: {45}--rwrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_34c49\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_34c49_level0_col0\" class=\"col_heading level0 col0\" >Pointing Game Scores</th>\n",
       "      <th id=\"T_34c49_level0_col1\" class=\"col_heading level0 col1\" >p-value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Explainer</th>\n",
       "      <th class=\"index_name level1\" >Detector</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_34c49_level0_row0\" class=\"row_heading level0 row0\" >LIME\\_Explainer</th>\n",
       "      <th id=\"T_34c49_level1_row0\" class=\"row_heading level1 row0\" >DetectorRadford</th>\n",
       "      <td id=\"T_34c49_row0_col0\" class=\"data row0 col0\" >0.402</td>\n",
       "      <td id=\"T_34c49_row0_col1\" class=\"data row0 col1\" >0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_34c49_level0_row1\" class=\"row_heading level0 row1\" >Random\\_Explainer</th>\n",
       "      <th id=\"T_34c49_level1_row1\" class=\"row_heading level1 row1\" >DetectorRadford</th>\n",
       "      <td id=\"T_34c49_row1_col0\" class=\"data row1 col0\" >0.484</td>\n",
       "      <td id=\"T_34c49_row1_col1\" class=\"data row1 col1\" >0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_34c49_level0_row2\" class=\"row_heading level0 row2\" >Anchor\\_Explainer</th>\n",
       "      <th id=\"T_34c49_level1_row2\" class=\"row_heading level1 row2\" >DetectorRadford</th>\n",
       "      <td id=\"T_34c49_row2_col0\" class=\"data row2 col0\" >0.492</td>\n",
       "      <td id=\"T_34c49_row2_col1\" class=\"data row2 col1\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_34c49_level0_row3\" class=\"row_heading level0 row3\" >SHAP\\_Explainer</th>\n",
       "      <th id=\"T_34c49_level1_row3\" class=\"row_heading level1 row3\" >DetectorRadford</th>\n",
       "      <td id=\"T_34c49_row3_col0\" class=\"data row3 col0\" >0.631</td>\n",
       "      <td id=\"T_34c49_row3_col1\" class=\"data row3 col1\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ac64a18cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bcc08_level0_col0, #T_bcc08_level0_col1 {\n",
       "  rotatebox: {45}--rwrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bcc08\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bcc08_level0_col0\" class=\"col_heading level0 col0\" >Pointing Game Scores</th>\n",
       "      <th id=\"T_bcc08_level0_col1\" class=\"col_heading level0 col1\" >p-value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Explainer</th>\n",
       "      <th class=\"index_name level1\" >Detector</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bcc08_level0_row0\" class=\"row_heading level0 row0\" >Random\\_Explainer</th>\n",
       "      <th id=\"T_bcc08_level1_row0\" class=\"row_heading level1 row0\" >DetectorDetectGPT</th>\n",
       "      <td id=\"T_bcc08_row0_col0\" class=\"data row0 col0\" >0.577</td>\n",
       "      <td id=\"T_bcc08_row0_col1\" class=\"data row0 col1\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcc08_level0_row1\" class=\"row_heading level0 row1\" >LIME\\_Explainer</th>\n",
       "      <th id=\"T_bcc08_level1_row1\" class=\"row_heading level1 row1\" >DetectorDetectGPT</th>\n",
       "      <td id=\"T_bcc08_row1_col0\" class=\"data row1 col0\" >0.631</td>\n",
       "      <td id=\"T_bcc08_row1_col1\" class=\"data row1 col1\" >0.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcc08_level0_row2\" class=\"row_heading level0 row2\" >SHAP\\_Explainer</th>\n",
       "      <th id=\"T_bcc08_level1_row2\" class=\"row_heading level1 row2\" >DetectorDetectGPT</th>\n",
       "      <td id=\"T_bcc08_row2_col0\" class=\"data row2 col0\" >0.635</td>\n",
       "      <td id=\"T_bcc08_row2_col1\" class=\"data row2 col1\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ac867fbd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "groupby = [\"Explainer\", \"Detector\"]\n",
    "\n",
    "latex_output.append(r\"\"\"\\begin{figure}\"\"\")\n",
    "for detector_class in detector_classes:\n",
    "    label = \"results_pointing_game_detector_\"+detector_class.__name__\n",
    "    caption = detector_class.__name__\n",
    "    df_random = dff_random.groupby(groupby + [\"doc_nr\"])[\"Pointing Game Scores\"].mean() if groupby != [\"Detector\"] else None\n",
    "\n",
    "\n",
    "    df_aggregate_results = pd.DataFrame([dff.groupby(groupby)[\"Pointing Game Scores\"].mean()]).T\n",
    "    df_aggregate_results = df_aggregate_results.reindex(sorted(df_aggregate_results.columns), axis=1)\n",
    "\n",
    "\n",
    "    df_random_row = pd.DataFrame(df_random.groupby(groupby).mean())\n",
    "    df_aggregate_results_ = pd.concat([df_aggregate_results[df_aggregate_results.index.get_level_values(1) == detector_class.__name__], df_random_row[df_random_row.index.get_level_values(1) == detector_class.__name__]])\n",
    "\n",
    "    \n",
    "    df_aggregate_results_.sort_values(by=\"Pointing Game Scores\", inplace=True, ascending=True)\n",
    "\n",
    "    p_values = []\n",
    "    itr = df_aggregate_results_.iterrows()\n",
    "    next(itr)\n",
    "    counts =  pd.concat([dff, dff_random]).groupby(groupby).count()\n",
    "    counts = counts.reset_index()\n",
    "    \n",
    "    for (name_current, p_current), (name_next, p_next) in zip(df_aggregate_results_.iterrows(), itr):\n",
    "        n=counts[(counts[groupby] == name_current).all(axis=1)].iloc[0][\"Pointing Game Scores\"]\n",
    "        name_current = name_current if len(groupby) >= 2 else [name_current]\n",
    "        p_values.append((*name_current, binomtest(int(p_current.values[0] * n), n=n, p=p_next.values[0], alternative=\"less\").pvalue))\n",
    "\n",
    "    result = df_aggregate_results_.join(pd.DataFrame(p_values, columns=[*groupby, \"p-value\"]).set_index(groupby)).fillna(\"\").style\\\n",
    "        .map_index(lambda v: \"rotatebox:{45}--rwrap;\", level=0, axis=1).format(precision=3).format_index(escape=\"latex\", axis=0)\n",
    "    latex_output.append(result.to_latex(environment=\"subfigure\", \n",
    "                                        convert_css=True, \n",
    "                                        clines=\"all;data\", \n",
    "                                        hrules=True, \n",
    "                                        caption=caption, \n",
    "                                        label=label))\n",
    "    display(result)\n",
    "latex_output.append(r\"\"\"\\caption{Results per detector. P-values from a binominal tests with $H_0$: No difference between this method and the next best in this list.}\"\"\")\n",
    "latex_output.append(r\"\"\"\\label{results_pointing_game_detector}\"\"\")\n",
    "latex_output.append(r\"\"\"\\end{figure}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_latex(string):\n",
    "    return string\\\n",
    "    .replace(\"_Explainer\", \"\")\\\n",
    "    .replace(\"DetectorRadford\", \"Radford\")\\\n",
    "    .replace(\"DetectorDetectGPT\", \"DetectGPT\")\\\n",
    "    .replace(\"DetectorGuo\", \"Guo\")\\\n",
    "    .replace(\"Pointing Game Scores\", \"Score\")\\\n",
    "    .replace(r\"\"\"\\begin{subfigure}\"\"\", r\"\"\"\\begin{subfigure}{\\columnwidth}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\begin{table}\\n\\\\caption{Results aggregated by explainer. P-values from a binominal tests with $H_0$: No difference between this method and the next best in this list.}\\n\\\\label{results_pointing_game_explainers}\\n\\\\begin{tabular}{lrl}\\n\\\\toprule\\n & Score & p-value \\\\\\\\\\nExplainer &  &  \\\\\\\\\\n\\\\midrule\\nLIME\\\\ & 0.546 & 0.143 \\\\\\\\\\n\\\\cline{1-3}\\nRandom\\\\ & 0.565 & 0.000 \\\\\\\\\\n\\\\cline{1-3}\\nAnchor\\\\ & 0.586 & 0.000 \\\\\\\\\\n\\\\cline{1-3}\\nSHAP\\\\ & 0.692 &  \\\\\\\\\\n\\\\cline{1-3}\\n\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{table}\\n',\n",
       " '\\\\begin{figure}',\n",
       " '{\\\\begin{subfigure}{\\\\columnwidth}\\n\\\\caption{Guo}\\n\\\\label{results_pointing_game_detector_Guo}\\n\\\\begin{tabular}{llrl}\\n\\\\toprule\\n &  & Score & p-value \\\\\\\\\\nExplainer & Detector &  &  \\\\\\\\\\n\\\\midrule\\nLIME\\\\ & Guo & 0.605 & 0.168 \\\\\\\\\\n\\\\cline{1-4} \\\\cline{2-4}\\nRandom\\\\ & Guo & 0.635 & 0.000 \\\\\\\\\\n\\\\cline{1-4} \\\\cline{2-4}\\nAnchor\\\\ & Guo & 0.681 & 0.000 \\\\\\\\\\n\\\\cline{1-4} \\\\cline{2-4}\\nSHAP\\\\ & Guo & 0.812 &  \\\\\\\\\\n\\\\cline{1-4} \\\\cline{2-4}\\n\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{subfigure}\\n',\n",
       " '{\\\\begin{subfigure}{\\\\columnwidth}\\n\\\\caption{Radford}\\n\\\\label{results_pointing_game_detector_Radford}\\n\\\\begin{tabular}{llrl}\\n\\\\toprule\\n &  & Score & p-value \\\\\\\\\\nExplainer & Detector &  &  \\\\\\\\\\n\\\\midrule\\nLIME\\\\ & Radford & 0.402 & 0.004 \\\\\\\\\\n\\\\cline{1-4} \\\\cline{2-4}\\nRandom\\\\ & Radford & 0.484 & 0.003 \\\\\\\\\\n\\\\cline{1-4} \\\\cline{2-4}\\nAnchor\\\\ & Radford & 0.492 & 0.000 \\\\\\\\\\n\\\\cline{1-4} \\\\cline{2-4}\\nSHAP\\\\ & Radford & 0.631 &  \\\\\\\\\\n\\\\cline{1-4} \\\\cline{2-4}\\n\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{subfigure}\\n',\n",
       " '{\\\\begin{subfigure}{\\\\columnwidth}\\n\\\\caption{DetectGPT}\\n\\\\label{results_pointing_game_detector_DetectGPT}\\n\\\\begin{tabular}{llrl}\\n\\\\toprule\\n &  & Score & p-value \\\\\\\\\\nExplainer & Detector &  &  \\\\\\\\\\n\\\\midrule\\nRandom\\\\ & DetectGPT & 0.577 & 0.000 \\\\\\\\\\n\\\\cline{1-4} \\\\cline{2-4}\\nLIME\\\\ & DetectGPT & 0.631 & 0.473 \\\\\\\\\\n\\\\cline{1-4} \\\\cline{2-4}\\nSHAP\\\\ & DetectGPT & 0.635 &  \\\\\\\\\\n\\\\cline{1-4} \\\\cline{2-4}\\n\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{subfigure}\\n',\n",
       " '\\\\caption{Results per detector. P-values from a binominal tests with $H_0$: No difference between this method and the next best in this list.}',\n",
       " '\\\\label{results_pointing_game_detector}',\n",
       " '\\\\end{figure}']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[shorten_latex(l) for l in latex_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"figures/tables_pointing_game.tex\", \"w\", encoding=\"UTF-8\") as text_file:\n",
    "    text_file.write(\"\\n\".join([shorten_latex(l) for l in latex_output]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
