{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "N_DEBUG = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from gpt2outputdataset.detector_radford import DetectorRadford\n",
    "from detector_guo import DetectorGuo\n",
    "from detector_dummy import DetectorDummy\n",
    "from explainer_wrappers import LIME_Explainer, SHAP_Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle(\"./dataset_test.pkl\")\n",
    "test = test # always load the full dataset! (np.random.shuffle(tokenized_sentences)). slice the actual hybrid_documents if debugging!\n",
    "\n",
    "\n",
    "documents = test[\"answer\"]\n",
    "gold_labels = test[\"author\"] == \"human_answers\" # convention: 0: machine, 1: human, see detector.py\n",
    "\n",
    "if  N_DEBUG > 0:\n",
    "    documents = documents[0:N_DEBUG]\n",
    "    gold_labels = gold_labels[0:N_DEBUG]\n",
    "\n",
    "#from gpt2outputdataset.detector_radford import DetectorRadford\n",
    "#from detectgpt.detector_detectgpt import DetectorDetectGPT\n",
    "\n",
    "detector_classes = [DetectorGuo,DetectorRadford]# DetectorDetectGPT]\n",
    "\n",
    "explainer_classes = [LIME_Explainer,SHAP_Explainer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "pattern = re.compile(r\"<extra_id_\\d+>\")\n",
    "\n",
    "\n",
    "\n",
    "model = \"t5-small\"\n",
    "cache_dir=\"./.cache\"\n",
    "mask_model = transformers.AutoModelForSeq2SeqLM.from_pretrained(model, cache_dir=cache_dir).to(DEVICE)\n",
    "mask_tokenizer = transformers.AutoTokenizer.from_pretrained(model, model_max_length=mask_model.config.n_positions, cache_dir=cache_dir)#.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"Detector\", \"Original\", \"Prompt\", \"Edited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate perturbed samples (similar to how it is done in detectgpt/detector_detectgpt.py)\n",
    "def get_pertubed_text(detector, text, n=1):\n",
    "    tokens = text.split(' ')\n",
    "    # select 1 (TODO) token in the original document to mask\n",
    "    mask = np.zeros_like(tokens, dtype=bool)\n",
    "    mask[np.random.randint(0, len(mask))] = 1 # TODO number of tokens to mask\n",
    "\n",
    "    prediction_original = detector.predict_label([text])[0]\n",
    "\n",
    "    past_generations = []\n",
    "    perturbed_text = text\n",
    "    # generate n unique perturbations (replace the same masked word(s) with one or more words)\n",
    "    for _ in range(0,n):\n",
    "        replacement_attempts = 0\n",
    "        while True: # do while \n",
    "    \n",
    "            i = 0\n",
    "            for ii, (m, token) in enumerate(zip(mask, tokens)):\n",
    "                if m:\n",
    "                    tokens[ii] = \"<extra_id_{}>\".format(i)\n",
    "                    i+=1\n",
    "            i-=1\n",
    "            masked_text = ' '.join(tokens)\n",
    "            stop_id = mask_tokenizer.encode(f\"<extra_id_{i+1}>\")[0]\n",
    "\n",
    "\n",
    "            tok = mask_tokenizer(masked_text, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
    "            outputs = mask_model.generate(**tok, max_length=150, do_sample=True, top_p=1, num_return_sequences=1, eos_token_id=stop_id,)\n",
    "            mt = mask_tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
    "\n",
    "            fills = [x for x in re.split(r\"<extra_id_\\d*>\", mt[0]) if x != \"<pad>\"]\n",
    "\n",
    "            for i, (token, m) in enumerate(zip(tokens, mask)):\n",
    "                if m:\n",
    "                    if replacement_attempts < 100:\n",
    "                        tokens[i] = fills.pop(0).strip()\n",
    "                    else: # sometimes t5 can't come up with 5 unique new perturbations that match the constraints below. use a random word from the vocabulary instead\n",
    "                        # have to change seed here as detector.predict_label() below sets it (wich results in endless loop)\n",
    "                        np.random.seed(replacement_attempts)\n",
    "                        random_token = [np.random.randint(0, mask_tokenizer.vocab_size)]\n",
    "                        np.random.seed(42) # reset seed just to be sure, is reset with the next detector.predict_label() anyways \n",
    "                        tokens[i] = mask_tokenizer.batch_decode(random_token, skip_special_tokens=False)[0]\n",
    "            perturbed_text = \" \".join(tokens)\n",
    "\n",
    "            # check if this is a valid and new perturbation\n",
    "            if (perturbed_text == text) or (perturbed_text in past_generations):\n",
    "                replacement_attempts+=1\n",
    "                continue\n",
    "            # check that label didn't flip\n",
    "            if detector.predict_label([perturbed_text])[0] != prediction_original:\n",
    "                replacement_attempts+=1\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        past_generations.append(perturbed_text)\n",
    "    return past_generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"Detector\", \"Original\", \"Perturbation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"./continuity.csv\"):\n",
    "    df = pd.read_csv(\"./continuity.csv\")\n",
    "else: \n",
    "    df = pd.DataFrame([], columns=columns)\n",
    "    # write headers (mode != \"a\")\n",
    "    df.to_csv(\"./continuity.csv\", encoding=\"UTF-8\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Generating perturbations: 100%|██████████| 305/305 [00:00<00:00, 1054.40it/s]\n",
      "Generating perturbations: 100%|██████████| 305/305 [00:00<00:00, 1212.50it/s]\n"
     ]
    }
   ],
   "source": [
    "N_PERTURBATIONS = 5\n",
    "\n",
    "\n",
    "for detector_class in detector_classes:\n",
    "    detector = detector_class()\n",
    "    for document in tqdm(documents, total=len(documents), desc=\"Generating perturbations\"):\n",
    "        if df[(df[\"Original\"] == document) & (df[\"Detector\"] == detector.__class__.__name__)][\"Original\"].count() > 0:\n",
    "            continue\n",
    "        # set seeds here so perturbed documents are the same regardless of slice for documents when debugging (and explanations don't have to be regenerated)\n",
    "        np.random.seed(42)\n",
    "        torch.manual_seed(42)\n",
    "        for perturbation in get_pertubed_text(detector, document, N_PERTURBATIONS):\n",
    "            row = ((detector.__class__.__name__, document, perturbation))\n",
    "            pd.DataFrame([row], columns=columns).to_csv(\"./continuity.csv\", mode=\"a\", encoding=\"UTF-8\", index=False, header=False)\n",
    "        #break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if DEBUG:\n",
    "#     # only keep instances with cached explanations\n",
    "#     explainers = [explainer_calss(detector) for explainer_calss in explainer_classes]\n",
    "#     documents_and_perturbations = [(original, gl, perturbations) for original, gl, perturbations in documents_and_perturbations if all([explainer.does_explanation_exist(original) for explainer in explainers]) and all([\n",
    "#     x\n",
    "#     for xs in [[explainer.does_explanation_exist(perturbation) for perturbation in perturbations] for explainer in explainers]\n",
    "#     for x in xs\n",
    "# ])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detector</th>\n",
       "      <th>Original</th>\n",
       "      <th>Perturbation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DetectorGuo</td>\n",
       "      <td>I've heard of handyman type people making a li...</td>\n",
       "      <td>I've heard of handyman type people making a li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DetectorGuo</td>\n",
       "      <td>I've heard of handyman type people making a li...</td>\n",
       "      <td>I've heard of handyman type people making a li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DetectorGuo</td>\n",
       "      <td>I've heard of handyman type people making a li...</td>\n",
       "      <td>I've heard of handyman type people making a li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DetectorGuo</td>\n",
       "      <td>I've heard of handyman type people making a li...</td>\n",
       "      <td>I've heard of handyman type people making a li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DetectorGuo</td>\n",
       "      <td>I've heard of handyman type people making a li...</td>\n",
       "      <td>I've heard of handyman type people making a li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3045</th>\n",
       "      <td>DetectorRadford</td>\n",
       "      <td>In financial markets, the terms \"bid\" and \"ask...</td>\n",
       "      <td>In financial markets, the terms \"bid\" and \"ask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>DetectorRadford</td>\n",
       "      <td>In financial markets, the terms \"bid\" and \"ask...</td>\n",
       "      <td>In financial markets, the terms \"bid\" and \"ask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>DetectorRadford</td>\n",
       "      <td>In financial markets, the terms \"bid\" and \"ask...</td>\n",
       "      <td>In financial markets, the terms \"bid\" and \"ask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>DetectorRadford</td>\n",
       "      <td>In financial markets, the terms \"bid\" and \"ask...</td>\n",
       "      <td>In financial markets, the terms \"bid\" and \"ask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>DetectorRadford</td>\n",
       "      <td>In financial markets, the terms \"bid\" and \"ask...</td>\n",
       "      <td>In financial markets, the terms \"bid\" and \"ask...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3050 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Detector                                           Original  \\\n",
       "0         DetectorGuo  I've heard of handyman type people making a li...   \n",
       "1         DetectorGuo  I've heard of handyman type people making a li...   \n",
       "2         DetectorGuo  I've heard of handyman type people making a li...   \n",
       "3         DetectorGuo  I've heard of handyman type people making a li...   \n",
       "4         DetectorGuo  I've heard of handyman type people making a li...   \n",
       "...               ...                                                ...   \n",
       "3045  DetectorRadford  In financial markets, the terms \"bid\" and \"ask...   \n",
       "3046  DetectorRadford  In financial markets, the terms \"bid\" and \"ask...   \n",
       "3047  DetectorRadford  In financial markets, the terms \"bid\" and \"ask...   \n",
       "3048  DetectorRadford  In financial markets, the terms \"bid\" and \"ask...   \n",
       "3049  DetectorRadford  In financial markets, the terms \"bid\" and \"ask...   \n",
       "\n",
       "                                           Perturbation  \n",
       "0     I've heard of handyman type people making a li...  \n",
       "1     I've heard of handyman type people making a li...  \n",
       "2     I've heard of handyman type people making a li...  \n",
       "3     I've heard of handyman type people making a li...  \n",
       "4     I've heard of handyman type people making a li...  \n",
       "...                                                 ...  \n",
       "3045  In financial markets, the terms \"bid\" and \"ask...  \n",
       "3046  In financial markets, the terms \"bid\" and \"ask...  \n",
       "3047  In financial markets, the terms \"bid\" and \"ask...  \n",
       "3048  In financial markets, the terms \"bid\" and \"ask...  \n",
       "3049  In financial markets, the terms \"bid\" and \"ask...  \n",
       "\n",
       "[3050 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./continuity.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate all explanations\n",
    "# for detector_class in detector_classes:\n",
    "#     detector = detector_class()\n",
    "#     print(detector.__class__.__name__)\n",
    "#     for explainer_class in explainer_classes:\n",
    "        \n",
    "#         explainer = explainer_class(detector)\n",
    "#         print(explainer.__class__.__name__)\n",
    "#         for original, perturbation in tqdm([(o, p) for o,p in zip(df[\"Original\"], df[\"Perturbation\"]) if not explainer.is_cached(o) or not explainer.is_cached(p) or not all([explainer.is_cached(o, alt=\"alt_{}_\".format(i)) for i in range(1,5)])]):\n",
    "#             explainer.get_explanation_cached(original)\n",
    "#             explainer.get_explanation_cached(perturbation)\n",
    "#             for i in range(1,4):\n",
    "#                 explainer.get_explanation_cached(original, alt=\"alt_{}_\".format(i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import krippendorff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list of tokens in the document, in an encoding that allows for treating explanations as observations in an experiment\n",
    "\n",
    "# in this experiment, words are treated as variables and fi-scores as responses in a coding task\n",
    "\n",
    "# this function therefore transforms a string \"An example is an example\"\n",
    "# into a list of pairs:\n",
    "# [(\"An\", 0), (\"example\", 0), (\"is\", 0), (\"an\", 0), (\"example\",1)]\n",
    "# \"An example is not an example\"\n",
    "# [(\"An\", 0), (\"example\", 0), (\"is\", 0), (\"not\", 0), (\"an\", 0), (\"example\",1)]\n",
    "\n",
    "# when calculating the reliability measure, replaced and/or missing words are treated as unobserved in the other explanations\n",
    "\n",
    "def get_tokens_with_pos(explainer, document):\n",
    "    p_counter = defaultdict(lambda : 0)\n",
    "    tokens_with_pos = []\n",
    "    for token in explainer.tokenize(document):\n",
    "        tokens_with_pos.append((token, p_counter[token]))\n",
    "        p_counter[token] += 1\n",
    "    return tokens_with_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as above, but also includes the position in the original document given by enumerate(explainer.tokenize(document))\n",
    "# this is useful for indexing the original explanation (a dict)\n",
    "def get_tokens_with_pos_and_id(explainer, document):\n",
    "    p_counter = defaultdict(lambda : 0)\n",
    "    tokens_with_pos = []\n",
    "    for id, token in enumerate(explainer.tokenize(document)):\n",
    "        tokens_with_pos.append((token, p_counter[token], id))\n",
    "        p_counter[token] += 1\n",
    "    return tokens_with_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_to_cannonical_form(experiment, explainer):\n",
    "    # build a list of tokens across [original] + edited; will be the \"cols\" of the \"cannocical_form\" matrix:\n",
    "    # each word is treated as an item, each explanation as an observation\n",
    "    global_tokens_with_pos = [get_tokens_with_pos(explainer, d) for d in experiment]\n",
    "    global_tokens_with_pos= list(set([x for xs in global_tokens_with_pos for x in xs]))\n",
    "\n",
    "    # this matrix will be passed to krippendorff.alpha as reliability_data\n",
    "    cannonical_form = np.empty((len(experiment),len(global_tokens_with_pos)))\n",
    "    cannonical_form[:] = np.nan # what is not filled is treated as unobserved\n",
    "\n",
    "    # fill this matrix\n",
    "    for n_experiment, document in enumerate(experiment):\n",
    "        tokens_with_pos_and_id = get_tokens_with_pos_and_id(explainer,document)\n",
    "        # the explanations are dicts of \"#word\": \"fi_score\"\n",
    "        fi_scores_dict = dict(explainer.get_fi_scores(document,fill=True)[0]) # [0] only consider explanation towards class \"machine\" for simplicity\n",
    "\n",
    "        # loop over the document, fill cells in cannonical_form\n",
    "        for token, pos, id_doc in tokens_with_pos_and_id:\n",
    "            t = (token, pos)\n",
    "            # look up the col in the matrix this word belongs to\n",
    "            col_in_cannonical_matrix = global_tokens_with_pos.index(t)\n",
    "\n",
    "            # check if the explanation provides a fi value for this word\n",
    "            if id_doc in fi_scores_dict:\n",
    "                cannonical_form[n_experiment, col_in_cannonical_matrix] = fi_scores_dict[id_doc]\n",
    "         #   else:\n",
    "                # any new word introduced in the edited documents is unobserved in the original document           \n",
    "      #  print(cannonical_form)\n",
    "    labels = [token + \"_\"+ str(pos) for token, pos in global_tokens_with_pos]\n",
    "    \n",
    "    return cannonical_form , labels #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_to_cannonical_form(experiment, explainer):\n",
    "    \n",
    "    # each word is treated as an item, each explanation as an observation\n",
    "    tokenized = [explainer.tokenize(d) for d in experiment]\n",
    "\n",
    "    fi_scores = [tuple(zip(*explainer.get_fi_scores(d,fill=True)[0]))[1] for d in experiment] # fi scores towards label machine\n",
    "    # determine bounds of left common part\n",
    "    i = 0\n",
    "    while all(x[0:i] == tokenized[0][0:i] for x in tokenized):\n",
    "        i+=1\n",
    "    i-=1\n",
    "    # determine bounds of right common part\n",
    "    j = 1\n",
    "    while all(x[-j:] == tokenized[0][-j:] for x in tokenized):\n",
    "        j+=1\n",
    "    j-=1\n",
    "   # print(i,j)\n",
    "   # print([len(f) for f in fi_scores])\n",
    "    # this matrix will be passed to krippendorff.alpha as reliability_data\n",
    "    left_part = np.vstack([e[0:i] for e in fi_scores])\n",
    "    if j > 0: \n",
    "        right_part = np.vstack([e[-j:] for e in fi_scores])\n",
    "        cannonical_form = np.hstack([left_part, right_part])\n",
    "    else: # if no tokens on the right part match\n",
    "        cannonical_form = left_part\n",
    "\n",
    "    return cannonical_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[] == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIME_Explainer DetectorGuo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating agreement:   0%|          | 0/305 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for detector_class in detector_classes:\n",
    "    detector = detector_class()\n",
    "    df_detector = df[df[\"Detector\"] == detector.__class__.__name__]\n",
    "    for explainer_class in explainer_classes:\n",
    "        explainer = explainer_class(detector)\n",
    "        print(explainer.__class__.__name__, detector.__class__.__name__)\n",
    "        for original, perturbations in tqdm(df_detector.groupby(\"Original\"), desc=\"Calculating agreement\"):\n",
    "            if not explainer.is_cached(original) or not all([explainer.is_cached(p) for p in perturbations[\"Perturbation\"].tolist() ]):\n",
    "                continue\n",
    "            cannonical_form = experiment_to_cannonical_form([original]+perturbations[\"Perturbation\"].tolist(), explainer)\n",
    "            #cannonical_form_rerun = experiment_to_cannonical_form([original]*5, explainer)\n",
    "            results.append((\n",
    "                explainer.__class__.__name__, \n",
    "                explainer.detector.__class__.__name__,\n",
    "                krippendorff.alpha(reliability_data=cannonical_form, level_of_measurement=\"interval\"),\n",
    "               # krippendorff.alpha(reliability_data=cannonical_form_rerun, level_of_measurement=\"interval\")\n",
    "                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results, columns=[\"Explainer\", \"Detector\", \"alpha\",])#\"alpha rerun\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Explainer</th>\n",
       "      <th>Detector</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIME_Explainer</td>\n",
       "      <td>DetectorGuo</td>\n",
       "      <td>0.337869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIME_Explainer</td>\n",
       "      <td>DetectorGuo</td>\n",
       "      <td>0.496127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LIME_Explainer</td>\n",
       "      <td>DetectorGuo</td>\n",
       "      <td>0.391412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LIME_Explainer</td>\n",
       "      <td>DetectorGuo</td>\n",
       "      <td>0.613203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIME_Explainer</td>\n",
       "      <td>DetectorGuo</td>\n",
       "      <td>0.554270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>SHAP_Explainer</td>\n",
       "      <td>DetectorRadford</td>\n",
       "      <td>0.927417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>SHAP_Explainer</td>\n",
       "      <td>DetectorRadford</td>\n",
       "      <td>0.899557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>SHAP_Explainer</td>\n",
       "      <td>DetectorRadford</td>\n",
       "      <td>0.654781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>SHAP_Explainer</td>\n",
       "      <td>DetectorRadford</td>\n",
       "      <td>0.898848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>SHAP_Explainer</td>\n",
       "      <td>DetectorRadford</td>\n",
       "      <td>0.563347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1087 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Explainer         Detector     alpha\n",
       "0     LIME_Explainer      DetectorGuo  0.337869\n",
       "1     LIME_Explainer      DetectorGuo  0.496127\n",
       "2     LIME_Explainer      DetectorGuo  0.391412\n",
       "3     LIME_Explainer      DetectorGuo  0.613203\n",
       "4     LIME_Explainer      DetectorGuo  0.554270\n",
       "...              ...              ...       ...\n",
       "1082  SHAP_Explainer  DetectorRadford  0.927417\n",
       "1083  SHAP_Explainer  DetectorRadford  0.899557\n",
       "1084  SHAP_Explainer  DetectorRadford  0.654781\n",
       "1085  SHAP_Explainer  DetectorRadford  0.898848\n",
       "1086  SHAP_Explainer  DetectorRadford  0.563347\n",
       "\n",
       "[1087 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Explainer</th>\n",
       "      <th>Detector</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LIME_Explainer</th>\n",
       "      <th>DetectorGuo</th>\n",
       "      <td>0.478115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DetectorRadford</th>\n",
       "      <td>0.439034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SHAP_Explainer</th>\n",
       "      <th>DetectorGuo</th>\n",
       "      <td>0.896235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DetectorRadford</th>\n",
       "      <td>0.824662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   alpha\n",
       "Explainer      Detector                 \n",
       "LIME_Explainer DetectorGuo      0.478115\n",
       "               DetectorRadford  0.439034\n",
       "SHAP_Explainer DetectorGuo      0.896235\n",
       "               DetectorRadford  0.824662"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.groupby([\"Explainer\", \"Detector\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Explainer</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LIME_Explainer</th>\n",
       "      <td>0.458575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAP_Explainer</th>\n",
       "      <td>0.870427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   alpha\n",
       "Explainer               \n",
       "LIME_Explainer  0.458575\n",
       "SHAP_Explainer  0.870427"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.set_index([\"Explainer\", \"Detector\"]).groupby([\"Explainer\"]).mean()\\\n",
    "    .to_latex(environment=\"longtable\", convert_css=True, clines=\"all;data\", hrules=True, caption=\"Results aggregated by explainer\", label=\"continuity-results-explainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_df.to_latex(environment=\"longtable\", convert_css=True, clines=\"all;data\", hrules=True, caption=\"Results aggregated by explainer\", label=\"continuity-results-explainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
