{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RANDOM_RUNS = 10\n",
    "USE_CACHE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from gpt2outputdataset.detector_radford import DetectorRadford\n",
    "from detectgpt.detector_detectgpt import DetectorDetectGPT\n",
    "from detector_guo import DetectorGuo\n",
    "from detector_dummy import DetectorDummy\n",
    "detector_classes = [DetectorGuo, DetectorRadford, DetectorDetectGPT]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle(\"./dataset_test.pkl\")\n",
    "train = pd.read_pickle(\"./dataset_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = test[\"answer\"]\n",
    "gold_labels = test[\"author\"] == \"human_answers\"\n",
    "\n",
    "\n",
    "# documents = documents[0:50]\n",
    "# gold_labels = gold_labels[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_cache = {}\n",
    "def prediction_cached(detector, documents):\n",
    "    if detector.__class__.__name__ not in prediction_cache:\n",
    "        prediction_cache[detector.__class__.__name__] = detector.predict_label(documents)\n",
    "    return prediction_cache[detector.__class__.__name__]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "if not USE_CACHE:\n",
    "    for n in range(0, N_RANDOM_RUNS):\n",
    "        for p_mask in [\"single\", 0.05, 0.1, 0.25,0.5,0.8]:\n",
    "            random.seed(42+n) # not that of numpy!\n",
    "            masked_documents = None\n",
    "            if p_mask != \"single\":\n",
    "                masked_documents = [\" \".join([t if random.random() > p_mask else \"<mask>\" for t in document.split(\" \")]) for document in documents]\n",
    "            else:\n",
    "                masked_documents = []\n",
    "                for document in documents:\n",
    "                    tokens = document.split(\" \")\n",
    "                    masked_documents.append(document.replace(random.sample(tokens,1)[0], \"<mask>\", 1))\n",
    "                \n",
    "            for detector_class in detector_classes:\n",
    "                detector = detector_class()\n",
    "                print(detector.__class__.__name__)\n",
    "                predictions_original = prediction_cached(detector, documents) # enables batching\n",
    "\n",
    "                experiments = {\n",
    "                    \"pad_token\": lambda text: \" \".join([t if t != \"<mask>\" else detector.get_pad_token() for t in text.split(\" \")]), # all share the custom mask token\n",
    "                    \"space\": lambda text: \" \".join([t if t != \"<mask>\" else \" \" for t in text.split(\" \")]),\n",
    "                    \"remove\": lambda text: \" \".join([t  for t in text.split(\" \") if t != \"<mask>\"]),\n",
    "                }\n",
    "                for e, f in experiments.items():\n",
    "                    print(\"       \", e, p_mask)\n",
    "                    np.random.seed(42)\n",
    "                    torch.manual_seed(42) \n",
    "                    predictions_masked = detector.predict_label([f(d) for d in masked_documents], deterministic=False) # enables batching\n",
    "\n",
    "                    for p_o, p_m, gt  in zip(predictions_original, predictions_masked, gold_labels):\n",
    "                        results.append((p_mask, detector.__class__.__name__, e, gt, p_o, p_m, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_CACHE:\n",
    "    df = pd.DataFrame(results, columns=[\"p_replace\", \"Detector\", \"Experiment\", \"GT\", \"original\", \"masked\", \"run\"])\n",
    "    df.to_csv(\"./masking_test_results.csv\", index=False)\n",
    "df = pd.read_csv(\"./masking_test_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"p_replace\"] == \"single\", \"p_replace\"] = 0.00001 # to enable sorting\n",
    "#df = df[df[\"p_replace\"] != \"single\"]\n",
    "df[\"p_replace\"] = df[\"p_replace\"].astype(float)\n",
    "# df = df.reset_index(drop=True).sort_values(by=\"p_replace\")\n",
    "# df[\"p_replace\"] = df[\"p_replace\"].astype(str)\n",
    "df[\"right_original\"] = df[\"GT\"] == df[\"original\"]\n",
    "df[\"right_masked\"] = df[\"GT\"] == df[\"masked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.groupby([\"Detector\", \"Experiment\", \"p_replace\", \"run\"])[\"masked\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = df[df[\"p_replace\"]== 0.05].copy()\n",
    "original[\"masked\"] = original[\"original\"]\n",
    "original[\"p_replace\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.concat([df,original])\n",
    "dfa = dfa.rename(columns={'masked': 'prediction',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa[\"GT\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, axes = plt.subplots(1,3, sharey=True, sharex=True, figsize=(15,5))\n",
    "# for ax, (experiment, group) in zip(axes, dfa.groupby([ \"Detector\"])):\n",
    "#     sns.violinplot(data=group, x=\"Experiment\", y=\"p_replace\", hue=\"prediction\", density_norm=\"count\",common_norm=True, inner=\"stick\",\n",
    "#                 split=True, fill=False,ax=ax\n",
    "#                 )\n",
    "#     ax.set_title(experiment[0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, axes = plt.subplots(1,3, sharey=True, sharex=True, figsize=(15,5))\n",
    "# for ax, (experiment, group) in zip(axes, dfa.groupby([ \"Detector\"])):\n",
    "#     sns.violinplot(data=group, x=\"Experiment\", y=\"p_replace\", hue=\"prediction\", density_norm=\"count\",common_norm=True, inner=\"stick\",\n",
    "#                 split=True, fill=False,ax=ax\n",
    "#                 )\n",
    "#     ax.set_title(experiment[0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.backends.backend_pgf import FigureCanvasPgf\n",
    "matplotlib.backend_bases.register_backend('pdf', FigureCanvasPgf)\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'sans-serif',\n",
    "    \"font.sans-serif\": \"Helvetica\",\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/70088196/two-sided-grouped-barplots-with-python-seaborn\n",
    "dfff = pd.DataFrame(dfa.reset_index(drop=True))\n",
    "dfff.loc[dfff[\"Experiment\"] == \"pad_token\", \"Experiment\"] = \"pad\"\n",
    "#dfff['Experiment'] = pd.Categorical(dfff['Experiment'])  # make hue column categorical, forcing a fixed order\n",
    "dfff = dfff[[\"prediction\", \"run\", \"p_replace\", \"Experiment\", \"Detector\"]]\n",
    "sns.set_palette(sns.color_palette(\"Set2\"))\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "outer = gridspec.GridSpec(1,3, wspace=0.0, hspace=0.2)\n",
    "first_ax = None\n",
    "for o, (detector, group) in zip(outer, dfff.groupby([\"Detector\", ])):\n",
    "    \n",
    "   # group = group.drop(\"run\", axis=1)\n",
    "   # group.loc[group[\"prediction\"] == 0, \"prediction\"] = -1\n",
    "   # display(group)\n",
    "   # display(group)\n",
    "    ax = plt.Subplot(fig, o)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5,1.01, detector[0],fontsize=12, weight='bold', ha='center')\n",
    "    fig.add_subplot(ax)\n",
    "    (i, ii) = gridspec.GridSpecFromSubplotSpec(1,2,subplot_spec=o, wspace=0.0, hspace=0.0)\n",
    "    ax1 = plt.Subplot(fig, i)\n",
    "    fig.add_subplot(ax1)\n",
    "    ax2 = plt.Subplot(fig, ii)\n",
    "    fig.add_subplot(ax2)\n",
    "    # draw adult subplot at the right\n",
    "    sns.barplot(data=group, x='prediction', y=\"p_replace\", hue='Experiment',estimator=lambda x : np.count_nonzero(x == 1)/N_RANDOM_RUNS,errorbar=\"ci\",\n",
    "                orient='horizontal', dodge=True, ax=ax2)\n",
    "    ax2.set_ylabel('')\n",
    "    ax2.set_xlabel('count f(x) = human')\n",
    "    ax2.tick_params(axis='y', labelright=False,  right=False, labelleft=False, left=False)\n",
    "    #ax2.set_title('  '+'human', loc='left')\n",
    "    ax2.legend_.remove() \n",
    "\n",
    "    sns.barplot(data=group, x='prediction',y=\"p_replace\", hue='Experiment',estimator=lambda x : np.count_nonzero(x == 0)/N_RANDOM_RUNS,errorbar=\"ci\",\n",
    "                orient='horizontal', dodge=True, ax=ax1)\n",
    "\n",
    "    # optionally use the same scale left and right\n",
    "    xmax = max(ax1.get_xlim()[1], ax2.get_xlim()[1])\n",
    "    ax1.set_xlim(xmax=xmax)\n",
    "    ax2.set_xlim(xmax=xmax)\n",
    "    if first_ax is None:\n",
    "        first_ax = ax1\n",
    "    \n",
    "    ax1.invert_xaxis() \n",
    "    ax1.tick_params(axis='y', labelright=False, right=False, labelleft=False, left=False)\n",
    "    ax1.set_ylabel('')\n",
    "    ax1.set_xlabel('count f(x) = machine')\n",
    "    ax1.set_xlim(None, 0)\n",
    "    ax1.legend_.remove()\n",
    "handles, labels = ax1.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', ncol=3, )\n",
    "\n",
    "\n",
    "first_ax.tick_params(axis='y', labelright=False, right=False, labelleft=True, left=True)\n",
    "first_ax.set_ylabel(\"masked\")\n",
    "labels = [\"{:.0f}\\%\".format(float(item.get_text())*100) for item in first_ax.get_yticklabels()]\n",
    "labels[1] = 'original'\n",
    "labels[1] = 'single'\n",
    "first_ax.set_yticklabels(labels)\n",
    "plt.savefig('./figures/masking.pgf')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change in Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_in_accuracy = df.groupby([\"Detector\", \"Experiment\", \"p_replace\", \"run\", \"GT\"]).apply(lambda g: g[\"right_masked\"].mean() - g[\"right_original\"].mean())\n",
    "change_in_accuracy\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "plt.suptitle(\"All\")\n",
    "sns.lineplot(data=pd.DataFrame(change_in_accuracy, columns=[\"change in acc when masking\"]), x=\"p_replace\", y=\"change in acc when masking\", hue=\"Experiment\", ax=ax, marker=\"o\")\n",
    "for detector, group in change_in_accuracy.groupby(\"Detector\"):\n",
    "    f, (ax_machine, ax_human) = plt.subplots(1,2, sharey=True, figsize=(10,5))\n",
    "    plt.suptitle(detector)\n",
    "    #     ax.plot(row.index.get_level_values(2), row.values, label=experiment)\n",
    "    \n",
    "    group = pd.DataFrame(group, columns=[\"change in acc when masking\"]).reset_index()\n",
    "    \n",
    "    #     ax.plot(row.index.get_level_values(2), row.values, label=experiment)\n",
    "    sns.lineplot(data=group[~group[\"GT\"]], x=\"p_replace\", y=\"change in acc when masking\", hue=\"Experiment\", ax=ax_machine, marker=\"o\")\n",
    "    sns.lineplot(data=group[group[\"GT\"]], x=\"p_replace\", y=\"change in acc when masking\", hue=\"Experiment\", ax=ax_human, marker=\"o\")\n",
    "    ax_machine.set_title(\"GT Machine\")\n",
    "    ax_human.set_title(\"GT Human\")\n",
    "    print(detector)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    f, ax = plt.subplots(sharey=True, figsize=(10,5))\n",
    "    sns.lineplot(data=group, x=\"p_replace\", y=\"change in acc when masking\", hue=\"Experiment\", ax=ax, marker=\"o\")\n",
    "    # ax.plot(g.index.get_level_values(0), g.values, label=str(n) + \" \" + str(name))\n",
    "        #ax.set_xticklabels([item.get_text().split(\",\")[0][1:] for item in ax.get_xticklabels()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Did the label flip?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_flip = df.groupby([\"Detector\", \"Experiment\", \"p_replace\", \"run\", \"GT\"]).apply(lambda g: (g[\"original\"] != g[\"masked\"]).mean())\n",
    "label_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax_machine, ax_human) = plt.subplots(1,2, sharey=True, figsize=(10,5))\n",
    "group = pd.DataFrame(label_flip, columns=[\"proportion label flip when x% removed\"]).reset_index()\n",
    "    \n",
    "    #     ax.plot(row.index.get_level_values(2), row.values, label=experiment)\n",
    "sns.lineplot(data=group[~group[\"GT\"]], x=\"p_replace\", y=\"proportion label flip when x% removed\", hue=\"Experiment\", ax=ax_machine)\n",
    "sns.lineplot(data=group[group[\"GT\"]], x=\"p_replace\", y=\"proportion label flip when x% removed\", hue=\"Experiment\", ax=ax_human)\n",
    "\n",
    "f, ax = plt.subplots(sharey=True, figsize=(10,5))\n",
    "group = pd.DataFrame(label_flip, columns=[\"proportion label flip when x% removed\"]).reset_index()\n",
    "    \n",
    "    #     ax.plot(row.index.get_level_values(2), row.values, label=experiment)\n",
    "sns.lineplot(data=group, x=\"p_replace\", y=\"proportion label flip when x% removed\", hue=\"Experiment\", ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for detector, group in label_flip.groupby(\"Detector\"):\n",
    "    f, (ax_machine, ax_human) = plt.subplots(1,2, sharey=True, figsize=(10,5))\n",
    "\n",
    "    # for experiment, row in group.groupby(\"Experiment\"):\n",
    "    group = pd.DataFrame(group, columns=[\"proportion label flip when x% removed\"]).reset_index()\n",
    "    \n",
    "    #     ax.plot(row.index.get_level_values(2), row.values, label=experiment)\n",
    "    sns.lineplot(data=group[~group[\"GT\"]], x=\"p_replace\", y=\"proportion label flip when x% removed\", hue=\"Experiment\", ax=ax_machine)\n",
    "    sns.lineplot(data=group[group[\"GT\"]], x=\"p_replace\", y=\"proportion label flip when x% removed\", hue=\"Experiment\", ax=ax_human)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    f, ax = plt.subplots(sharey=True, figsize=(10,5))\n",
    "    sns.lineplot(data=group, x=\"p_replace\", y=\"proportion label flip when x% removed\", hue=\"Experiment\", ax=ax)\n",
    "    # ax.plot(g.index.get_level_values(0), g.values, label=str(n) + \" \" + str(name))\n",
    "        #ax.set_xticklabels([item.get_text().split(\",\")[0][1:] for item in ax.get_xticklabels()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion (Old)\n",
    "No masking strategy works best across all detectors and percentages masked. Note that none of these detectors were trained to support partial data. \n",
    "The masking strategy \"pad_token\" is chosen for both LIME and SHAP for the following reasons:\n",
    "- In SHAP, this is the method demonstrated in the documentation for transformer based models: [Doc 1](https://shap.readthedocs.io/en/latest/example_notebooks/text_examples/sentiment_analysis/Using%20custom%20functions%20and%20tokenizers.html) [Doc 2](https://shap.readthedocs.io/en/latest/example_notebooks/text_examples/sentiment_analysis/Emotion%20classification%20multiclass%20example.html)\n",
    "- For LIME, the default is either removing words or replacing them with a (user-defined) masking string. For the detector of Guo et al., \"multiple space characters\" appear to be an important feature utilized for detection (see discussion on H3 dataset). Using a masking string is therefore preferred over the removal of tokens or the addition of spaces here. LIME would otherwise be unable to highlight that feature as spaces (the sep token) are always collapsed in the default implementation.\n",
    "- In the unprocessed dataset, human and ChatGPT-generated answers differed significantly in their average lengths. The last subplot here suggests that the detector from Guo et al. might utilize this fact (removing tokens does not flip the label for GT=human). Masking via the attention mask retains the length of the text. LIME would also collapse spaces.\n",
    "\n",
    "To summarize: The best masking strategy differs by detector and percentage of words masked. Masking via the pad_token is selected as it does not lead LIME to ignore the feature \"multiple spaces\", which would make its explanations unfaithful by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
