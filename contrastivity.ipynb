{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "N_DEBUG = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "import torch\n",
    "import re\n",
    "import sklearn\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle(\"./dataset_test.pkl\")\n",
    "\n",
    "test = test[test[\"author\"] == \"human_answers\"]\n",
    "print(\"len(test_human)\", len(test))\n",
    "documents = test[\"answer\"]\n",
    "gold_labels = test[\"author\"] == \"human_answers\" # convention: 0: machine, 1: human, see detector.py\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from gpt2outputdataset.detector_radford import DetectorRadford\n",
    "#from detectgpt.detector_detectgpt import DetectorDetectGPT\n",
    "from detector_guo import DetectorGuo\n",
    "detector_classes = [DetectorGuo]#,DetectorRadford,DetectorDetectGPT]\n",
    "\n",
    "from explainer_wrappers import LIME_Explainer, SHAP_Explainer\n",
    "explainer_classes = [LIME_Explainer,SHAP_Explainer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt2outputdataset.detector_radford import DetectorRadford\n",
    "\n",
    "\n",
    "detector = DetectorRadford()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "pattern = re.compile(r\"<extra_id_\\d+>\")\n",
    "\n",
    "base_model_name=\"facebook/opt-350m\"\n",
    "openai_model = False\n",
    "\n",
    "cache_dir=\"./.cache\"\n",
    "# mask_model = transformers.AutoModelForSeq2SeqLM.from_pretrained(model, cache_dir=cache_dir).to(DEVICE)\n",
    "# mask_tokenizer = transformers.AutoTokenizer.from_pretrained(model, model_max_length=mask_model.config.n_positions, cache_dir=cache_dir)#.to(DEVICE)\n",
    "do_top_k= False\n",
    "do_top_p= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_kwargs = {}\n",
    "if 'gpt-j' in base_model_name or 'neox' in base_model_name:\n",
    "    base_model_kwargs.update(dict(torch_dtype=torch.float16))\n",
    "if 'gpt-j' in base_model_name:\n",
    "    base_model_kwargs.update(dict(revision='float16'))\n",
    "base_model = transformers.AutoModelForCausalLM.from_pretrained(base_model_name, **base_model_kwargs, cache_dir=cache_dir).to(DEVICE)\n",
    "\n",
    "\n",
    "optional_tok_kwargs = {\"additional_special_tokens\": [\"<|loris|>\"]}\n",
    "# if \"facebook/opt-\" in base_model_name:\n",
    "#     print(\"Using non-fast tokenizer for OPT\")\n",
    "#     optional_tok_kwargs['fast'] = False\n",
    "\n",
    "base_tokenizer = transformers.AutoTokenizer.from_pretrained(base_model_name, **optional_tok_kwargs, cache_dir=cache_dir, padding_side='left')\n",
    "base_tokenizer.pad_token_id = base_tokenizer.eos_token_id # TODO WHY??? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG and N_DEBUG > 0:\n",
    "    documents = documents.iloc[0:N_DEBUG].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_flip_pairs = []\n",
    "\n",
    "for document in tqdm(documents, desc=\"Generating perturbations\"):\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    doc = nlp(document)\n",
    "    n_tokens_original = len(base_tokenizer(document, return_tensors=\"pt\", padding=True).to(DEVICE).input_ids[0])\n",
    "    original_prediction = detector.predict_label([document])[0]\n",
    "    substrings = [''.join(token.text_with_ws for token in doc[:-i]) for i in range(1,len(document)) ]\n",
    "\n",
    "    batch_size = 25\n",
    "    for batch in (sklearn.utils.gen_batches(len(substrings), batch_size)):\n",
    "        encoded = base_tokenizer(substrings[batch], return_tensors=\"pt\", padding=True).to(DEVICE)\n",
    "        sampling_kwargs = {}\n",
    "\n",
    "        outputs = base_model.generate(**encoded, min_length=n_tokens_original-5, max_length=n_tokens_original+5, do_sample=True, **sampling_kwargs, pad_token_id=base_tokenizer.eos_token_id, eos_token_id=base_tokenizer.eos_token_id)\n",
    "        decoded = base_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        predictions = detector.predict_label(decoded)\n",
    "        \n",
    "        if any(predictions != original_prediction):\n",
    "            first_new_label = (predictions!=original_prediction).argmax(axis=0)\n",
    "\n",
    "            #                        original  prompt                              first instance that flips label\n",
    "            label_flip_pairs.append((document, substrings[batch][first_new_label], decoded[first_new_label]))\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_flip_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = SHAP_Explainer(detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original, prompt, label_flip_example = label_flip_pairs[2]\n",
    "print(prompt)\n",
    "display(HTML(explainer.get_highlighted_text_HTML(original)))\n",
    "display(HTML(explainer.get_highlighted_text_HTML(prompt)))\n",
    "display(HTML(explainer.get_highlighted_text_HTML(label_flip_example)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic idea: assert that exp(original)[original - prompt] <substantially different than> exp(label_flip_example)[label_flip_example - prompt]\n",
    "# i.e. the new/changed section is assigned the opposite label (TODO hard coded: \"machine\") more often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_flip_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regen If your counterparty sent money to a correspondent account at another bank, then it is completely up to the other bank what to do with the money. If the wire transfer completed, then the account is not closed. If I were your business partner, I would immediately contact the bank to which the transfer was made and explain the situation and hopefully they will transfer the money back. Whenever a wire transfer is made, the recipients name, address, and account number are included.   I would not trust the money transfer company.\n",
      "I don't want to send the money to a new bank, so this means I cannot be the target of a bank subpoena. The bank is on paper with the account number and all the details of the transfer, and\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for explainer_class in explainer_classes:\n",
    "        explainer = explainer_class(detector)\n",
    "        for original, prompt, label_flip_example in label_flip_pairs:\n",
    "            tokens_original_minus_prompt = explainer.tokenize(original)[len(explainer.tokenize(prompt)):]\n",
    "            tokens_label_flip_minus_prompt = explainer.tokenize(label_flip_example)[len(explainer.tokenize(prompt)):]\n",
    "            exp_original_minus_prompt = explainer.get_fi_scores(original, fill=True)[0][len(explainer.tokenize(prompt)):] # TODO hard coded: \"machine\"\n",
    "            exp_label_flip_minus_prompt = explainer.get_fi_scores(label_flip_example, fill=True)[0][len(explainer.tokenize(prompt)):] # setting fill=True returns all features (not just the top_k) \n",
    "         \n",
    "            exp_original_prompt_only = explainer.get_fi_scores(original, fill=True)[0][0:len(explainer.tokenize(prompt))]\n",
    "            exp_label_flip_prompt_only = explainer.get_fi_scores(label_flip_example, fill=True)[0][0:len(explainer.tokenize(prompt))]\n",
    "           # print(exp_original_minus_prompt)\n",
    "           # print(exp_label_flip_minus_prompt)\n",
    "            mean_fi_machine_label_flip = np.mean([fi_score for _, fi_score in exp_label_flip_minus_prompt])\n",
    "            mean_fi_original = np.mean([fi_score for _, fi_score in exp_original_minus_prompt])\n",
    "\n",
    "            cannonical_form = np.vstack([exp_original_prompt_only, exp_label_flip_prompt_only])\n",
    "            k_alpha = krippendorff.alpha(cannonical_form, level_of_measurement=\"interval\")\n",
    "            results.append((explainer.__class__.__name__, k_alpha, mean_fi_original, mean_fi_machine_label_flip,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=[\"Explainer\", \"Krippendorf's alpha on prompt\",\"E[original - prompt]\", \"E[lf - prompt]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Change original -> lf [%]\"] = ((df[\"E[original - prompt]\"] - df[\"E[lf - prompt]\"] ) / df[\"E[original - prompt]\"]) * 100\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Explainer\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([fi_score for _, fi_score in exp_label_flip_minus_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_label_flip_minus_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
