{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"large\", \"small\", \"circular\", \"giant\", \"gigantic\", \"massive\", \"huge\", \"enormous\", \"circular\", \"rectangular\", \"rectangle\", \"wooden\", \"tiny\", \"oval\", \"size\", \"shaped\", \"oak\", \"marble\", \"big\", \"structure\", \"miniature\", \"compact\", \"shape\", \"bronze\", \"center\", \"white_stone\", \"white\", \"centre\", \"columns\", \"diameter\", \"skeleton\", \"triangle\", \"square\", \"granite\", \"brass\", \"sized\", \"ornate\", \"adorned\", \"bordered\", \"towers\", \"giant\", \"ginormous\", \"golden\", \"spanned\", \"sleek\", \"width\", \"marble\", \"medium\", \"larger\", \"silver\", \"antique\", \"obsidian\", \"squares\", \"smaller\", \"shiny\", \"circumference\", \"hourglass\", \"round\", \"flooring\", \"plush\", \"decoration\", \"sized\", \"exterior\", \"pillars\", \"walnut\", \"decorated\", \"bulky\", \"white_marble\", \"largest\", \"carpeted\", \"intricate_designs\", \"very_center\", \"black_stone\", \"medium\", \"yellow\", \"ivory\", \"average_size\", \"solid\", \"dotted\", \"silver\", \"bamboo\", \"dark_wood\", \"humongous\", \"comprised\", \"pure_gold\", \"crescent\", \"decorative\", \"curved\", \"gold\", \"outlined\", \"four_feet\", \"branching\", \"medium_size\", \"vertical\", \"interior\", \"coloured\", \"carvings\", \"dwarfed\", \"lined\", \"black\"]\n",
      "[\"good\", \"awful\", \"terrible\", \"great\", \"horrible\", \"bad\", \"fantastic\", \"amazing\", \"wonderful\", \"nice\", \"weird\", \"horrid\", \"perfect\", \"ridiculous\", \"unbelievable\", \"stupid\", \"awesome\", \"actually\", \"just_the_way\", \"strange\", \"funny\", \"dreadful\", \"clich\\u00e9\", \"predictable\", \"disappointing\", \"embarrassing\", \"incredible\", \"happy\", \"cool\", \"annoying\", \"outrageous\", \"shitty\", \"fun\", \"special\", \"horrendous\", \"humiliating\", \"atrocious\", \"lovely\", \"fabulous\", \"though\", \"spectacular\", \"different\", \"terrific\", \"odd\", \"honestly\", \"exciting\", \"brilliant\", \"tough\", \"scary\", \"pretty\", \"silly\", \"interesting\", \"disgusting\", \"legit\", \"hypocritical\", \"promising\", \"troublesome\", \"rediculous\", \"wierd\", \"lame\", \"boring\", \"much\", \"easy\", \"better\", \"phenomenal\", \"frustrating\", \"unfair\", \"true\", \"important\", \"mean\", \"unreal\", \"morbid\", \"exhausting\", \"thrilling\", \"lousy\", \"Funny\", \"beautiful\", \"splendid\", \"ironic\", \"likeable\", \"clich\\u00e9\", \"flattering\", \"cheesy\", \"helpful\", \"depressing\", \"stereotypical\", \"glamorous\", \"Honestly\", \"much\", \"poetic\", \"bizarre\", \"marvelous\", \"absurd\", \"sweet\", \"pleasant\"]\n",
      "[\"Because\", \"though\", \"understand\", \"actually\", \"honestly\", \"anyway\", \"mean\", \"probably\", \"thought\", \"If\", \"Maybe\", \"consider\", \"Obviously\", \"believe\", \"guess\", \"either\", \"suppose\", \"knowing\", \"Honestly\", \"anything\", \"doubt\", \"though\", \"seem\", \"definitely\", \"Or\", \"Besides\", \"maybe\", \"reason\", \"knew\", \"either\", \"anyone\", \"trust\", \"meant\", \"anymore\", \"Actually\", \"expect\", \"might\", \"seriously\", \"Now\", \"should\", \"certainly\", \"yet\", \"Although\", \"Plus\", \"Though\", \"assume\", \"fact\", \"unless\", \"care\", \"Not\", \"obviously\", \"Yet\", \"Though\", \"especially\", \"why\", \"cause\", \"always\", \"although\", \"admit\", \"Clearly\", \"Well\", \"cause\", \"accept\", \"possibly\", \"wish\", \"necessarily\", \"agree\", \"exactly\", \"idea\", \"suspect\", \"Besides\"]\n",
      "[\"logical\", \"reasonable\", \"rational\", \"plausible\", \"illogical\", \"unreasonable\", \"absurd\", \"questionable\", \"justified\", \"straightforward\", \"critical\", \"understandable\", \"doubtful\", \"troubling\", \"practical\", \"accurate\", \"ludicrous\", \"laughable\", \"intentional\", \"beneficial\", \"unnecessary\", \"discreet\", \"probable\", \"untrue\", \"legitimate\", \"sensible\", \"irrelevant\", \"implied\", \"outrageous\", \"logically\", \"problematic\", \"improbable\", \"compromised\", \"forthcoming\", \"preposterous\", \"adequate\", \"relevant\", \"agreeable\", \"vague\", \"definite\", \"irrational\", \"imply\", \"believable\", \"tolerant\", \"diplomatic\", \"admirable\", \"false\", \"inaccurate\", \"effective\", \"competent\", \"contrary\", \"convinced\", \"trivial\", \"unavoidable\", \"incompetent\", \"cooperative\", \"truthful\", \"valid\", \"obvious\", \"crucial\", \"insulting\", \"disconcerting\", \"bizarre\", \"impractical\", \"reliable\", \"inadequate\", \"improper\", \"inconsequential\", \"discouraged\", \"appealing\", \"certain\", \"adamant\", \"unlikely\", \"affected\", \"consistent\", \"knowledgeable\", \"unimportant\", \"troublesome\", \"worrying\", \"rationalized\", \"barbaric\", \"appalling\", \"incorrect\", \"meaningless\", \"disappointing\", \"reasoning\", \"inconvenient\", \"indifferent\", \"sceptical\", \"aggravating\", \"shameful\", \"predictable\", \"justify\", \"distasteful\", \"satisfactory\", \"extreme\", \"feasible\", \"lenient\", \"cryptic\", \"unprofessional\"]\n",
      "[\"practical\", \"wise\", \"logical\", \"beneficial\", \"certainly\", \"legitimate\", \"probable\", \"reasonable\", \"honorable\", \"profession\", \"mindset\", \"irrelevant\", \"certain\", \"questionable\", \"significant\", \"exceptional\", \"necessarily\", \"ideal\", \"Because\", \"morally\", \"suppose\", \"equal\", \"rational\", \"worthy\", \"though\", \"adequate\", \"unreasonable\", \"morals\", \"meant\", \"important\", \"potential\", \"ideal\", \"acceptable\", \"absurd\", \"outrageous\", \"necessity\", \"critical\", \"intentional\", \"crucial\", \"true\", \"superior\", \"norm\", \"sensible\", \"Though\", \"occupation\", \"Though\", \"illegal\", \"religious\", \"unfortunate\", \"successful\", \"superstitious\", \"unfit\", \"privileged\", \"compatible\", \"potential\", \"reliable\", \"definite\", \"trustworthy\", \"relevant\", \"compromised\", \"troublesome\", \"saint\", \"regardless\", \"responsible\", \"technical\", \"unacceptable\", \"qualified\", \"knowledgeable\", \"upbringing\", \"Or\", \"actuality\", \"Moreover\", \"superficial\", \"circumstance\", \"benefit\", \"respectable\", \"mentality\", \"educated\", \"meant\", \"submissive\", \"imply\", \"rightly\", \"contrary\", \"admirable\", \"definitely\", \"either\", \"dependent\", \"harmful\", \"fairness\", \"motive\", \"psychic\", \"appeal\", \"deserving\"]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# from gpt2outputdataset.detector_radford import DetectorRadford\n",
    "# from detectgpt.detector_detectgpt import DetectorDetectGPT#\n",
    "#from detector_guo import DetectorGuo\n",
    "from froehling.detector_froehling import DetectorFroehling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle(\"./dataset_test.pkl\")\n",
    "train = pd.read_pickle(\"./dataset_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = test[\"answer\"]\n",
    "gold_labels = test[\"author\"] == \"human_answers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting extraction of empath stats...\n",
      "... empath extracted!\n",
      "Starting extraction of Q-stats...\n",
      "   0% finished --- Total Time:     0.07 --- Checkpoint Time:     0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1% finished --- Total Time:     0.65 --- Checkpoint Time:     0.58\n",
      "   2% finished --- Total Time:     1.23 --- Checkpoint Time:     0.58\n",
      "   3% finished --- Total Time:     1.82 --- Checkpoint Time:     0.59\n",
      "   4% finished --- Total Time:     2.42 --- Checkpoint Time:     0.60\n",
      "   5% finished --- Total Time:     3.00 --- Checkpoint Time:     0.58\n",
      "   6% finished --- Total Time:     3.58 --- Checkpoint Time:     0.58\n",
      "   7% finished --- Total Time:     4.17 --- Checkpoint Time:     0.59\n",
      "   8% finished --- Total Time:     4.77 --- Checkpoint Time:     0.60\n",
      "   9% finished --- Total Time:     5.34 --- Checkpoint Time:     0.56\n",
      "  10% finished --- Total Time:     5.97 --- Checkpoint Time:     0.63\n",
      "  11% finished --- Total Time:     6.57 --- Checkpoint Time:     0.60\n",
      "  12% finished --- Total Time:     7.15 --- Checkpoint Time:     0.58\n",
      "  13% finished --- Total Time:     7.71 --- Checkpoint Time:     0.56\n",
      "  14% finished --- Total Time:     8.30 --- Checkpoint Time:     0.58\n",
      "  15% finished --- Total Time:     8.90 --- Checkpoint Time:     0.61\n",
      "  16% finished --- Total Time:     9.54 --- Checkpoint Time:     0.64\n",
      "  17% finished --- Total Time:    10.17 --- Checkpoint Time:     0.63\n",
      "  18% finished --- Total Time:    10.75 --- Checkpoint Time:     0.58\n",
      "  19% finished --- Total Time:    11.34 --- Checkpoint Time:     0.58\n",
      "  20% finished --- Total Time:    11.97 --- Checkpoint Time:     0.63\n",
      "  21% finished --- Total Time:    12.59 --- Checkpoint Time:     0.61\n",
      "  22% finished --- Total Time:    13.18 --- Checkpoint Time:     0.59\n",
      "  23% finished --- Total Time:    13.77 --- Checkpoint Time:     0.59\n",
      "  24% finished --- Total Time:    14.38 --- Checkpoint Time:     0.60\n",
      "  25% finished --- Total Time:    14.96 --- Checkpoint Time:     0.58\n",
      "  26% finished --- Total Time:    15.58 --- Checkpoint Time:     0.62\n",
      "  27% finished --- Total Time:    16.14 --- Checkpoint Time:     0.57\n",
      "  28% finished --- Total Time:    16.77 --- Checkpoint Time:     0.63\n",
      "  29% finished --- Total Time:    17.36 --- Checkpoint Time:     0.58\n",
      "  30% finished --- Total Time:    17.91 --- Checkpoint Time:     0.55\n",
      "  31% finished --- Total Time:    18.51 --- Checkpoint Time:     0.61\n",
      "  32% finished --- Total Time:    19.16 --- Checkpoint Time:     0.65\n",
      "  33% finished --- Total Time:    19.75 --- Checkpoint Time:     0.59\n",
      "  34% finished --- Total Time:    20.37 --- Checkpoint Time:     0.62\n",
      "  35% finished --- Total Time:    20.96 --- Checkpoint Time:     0.59\n",
      "  36% finished --- Total Time:    21.54 --- Checkpoint Time:     0.58\n",
      "  37% finished --- Total Time:    22.16 --- Checkpoint Time:     0.62\n",
      "  38% finished --- Total Time:    22.76 --- Checkpoint Time:     0.60\n",
      "  39% finished --- Total Time:    23.40 --- Checkpoint Time:     0.64\n",
      "  40% finished --- Total Time:    23.97 --- Checkpoint Time:     0.57\n",
      "  41% finished --- Total Time:    24.56 --- Checkpoint Time:     0.59\n",
      "  42% finished --- Total Time:    25.17 --- Checkpoint Time:     0.60\n",
      "  44% finished --- Total Time:    25.76 --- Checkpoint Time:     0.60\n",
      "  45% finished --- Total Time:    26.35 --- Checkpoint Time:     0.59\n",
      "  46% finished --- Total Time:    26.91 --- Checkpoint Time:     0.56\n",
      "  47% finished --- Total Time:    27.49 --- Checkpoint Time:     0.58\n",
      "  48% finished --- Total Time:    28.05 --- Checkpoint Time:     0.57\n",
      "  49% finished --- Total Time:    28.69 --- Checkpoint Time:     0.63\n",
      "  50% finished --- Total Time:    29.31 --- Checkpoint Time:     0.62\n",
      "  51% finished --- Total Time:    29.93 --- Checkpoint Time:     0.62\n",
      "  52% finished --- Total Time:    30.61 --- Checkpoint Time:     0.69\n",
      "  53% finished --- Total Time:    31.23 --- Checkpoint Time:     0.61\n",
      "  54% finished --- Total Time:    31.88 --- Checkpoint Time:     0.66\n",
      "  55% finished --- Total Time:    32.50 --- Checkpoint Time:     0.62\n",
      "  56% finished --- Total Time:    33.22 --- Checkpoint Time:     0.72\n",
      "  57% finished --- Total Time:    34.00 --- Checkpoint Time:     0.78\n",
      "  58% finished --- Total Time:    34.63 --- Checkpoint Time:     0.63\n",
      "  59% finished --- Total Time:    35.24 --- Checkpoint Time:     0.61\n",
      "  60% finished --- Total Time:    35.84 --- Checkpoint Time:     0.60\n",
      "  61% finished --- Total Time:    36.43 --- Checkpoint Time:     0.59\n",
      "  62% finished --- Total Time:    37.08 --- Checkpoint Time:     0.65\n",
      "  63% finished --- Total Time:    37.71 --- Checkpoint Time:     0.63\n",
      "  64% finished --- Total Time:    38.26 --- Checkpoint Time:     0.55\n",
      "  65% finished --- Total Time:    38.85 --- Checkpoint Time:     0.59\n",
      "  66% finished --- Total Time:    39.49 --- Checkpoint Time:     0.64\n",
      "  67% finished --- Total Time:    40.06 --- Checkpoint Time:     0.57\n",
      "  68% finished --- Total Time:    40.63 --- Checkpoint Time:     0.57\n",
      "  69% finished --- Total Time:    41.23 --- Checkpoint Time:     0.60\n",
      "  70% finished --- Total Time:    41.81 --- Checkpoint Time:     0.58\n",
      "  71% finished --- Total Time:    42.42 --- Checkpoint Time:     0.61\n",
      "  72% finished --- Total Time:    43.02 --- Checkpoint Time:     0.61\n",
      "  73% finished --- Total Time:    43.60 --- Checkpoint Time:     0.57\n",
      "  74% finished --- Total Time:    44.17 --- Checkpoint Time:     0.57\n",
      "  75% finished --- Total Time:    44.74 --- Checkpoint Time:     0.57\n",
      "  76% finished --- Total Time:    45.33 --- Checkpoint Time:     0.59\n",
      "  77% finished --- Total Time:    45.94 --- Checkpoint Time:     0.62\n",
      "  78% finished --- Total Time:    46.57 --- Checkpoint Time:     0.63\n",
      "  79% finished --- Total Time:    47.17 --- Checkpoint Time:     0.60\n",
      "  80% finished --- Total Time:    47.77 --- Checkpoint Time:     0.60\n",
      "  81% finished --- Total Time:    48.35 --- Checkpoint Time:     0.57\n",
      "  82% finished --- Total Time:    48.92 --- Checkpoint Time:     0.58\n",
      "  83% finished --- Total Time:    49.50 --- Checkpoint Time:     0.57\n",
      "  84% finished --- Total Time:    50.10 --- Checkpoint Time:     0.60\n",
      "  85% finished --- Total Time:    50.66 --- Checkpoint Time:     0.57\n",
      "  86% finished --- Total Time:    51.23 --- Checkpoint Time:     0.57\n",
      "  88% finished --- Total Time:    51.79 --- Checkpoint Time:     0.56\n",
      "  89% finished --- Total Time:    52.38 --- Checkpoint Time:     0.59\n",
      "  90% finished --- Total Time:    52.93 --- Checkpoint Time:     0.55\n",
      "  91% finished --- Total Time:    53.54 --- Checkpoint Time:     0.61\n",
      "  92% finished --- Total Time:    54.16 --- Checkpoint Time:     0.62\n",
      "  93% finished --- Total Time:    54.73 --- Checkpoint Time:     0.57\n",
      "  94% finished --- Total Time:    55.35 --- Checkpoint Time:     0.62\n",
      "  95% finished --- Total Time:    55.89 --- Checkpoint Time:     0.54\n",
      "  96% finished --- Total Time:    56.50 --- Checkpoint Time:     0.60\n",
      "  97% finished --- Total Time:    57.08 --- Checkpoint Time:     0.59\n",
      "  98% finished --- Total Time:    57.66 --- Checkpoint Time:     0.58\n",
      "  99% finished --- Total Time:    58.23 --- Checkpoint Time:     0.57\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (179645, 2) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m detector \u001b[38;5;241m=\u001b[39m \u001b[43mDetectorFroehling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manswer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\loris\\thesis\\froehling\\detector_froehling.py:145\u001b[0m, in \u001b[0;36mDetectorFroehling.__init__\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_path,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize)):\n\u001b[0;32m    143\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_path,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize))\n\u001b[1;32m--> 145\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_QStats.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mQ_stats\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\loris\\thesis\\.venv\\Lib\\site-packages\\numpy\\lib\\npyio.py:545\u001b[0m, in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    542\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m--> 545\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    546\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_array(fid, arr, allow_pickle\u001b[38;5;241m=\u001b[39mallow_pickle,\n\u001b[0;32m    547\u001b[0m                        pickle_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(fix_imports\u001b[38;5;241m=\u001b[39mfix_imports))\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (179645, 2) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "detector = DetectorFroehling(train[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.predict_proba([\"test loris loris\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install stanza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ihui54rf89iolks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mihui54rf89iolks\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ihui54rf89iolks' is not defined"
     ]
    }
   ],
   "source": [
    "ihui54rf89iolks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detector = DetectorRadford()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.7375951e-04, 9.9972624e-01]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.predict_proba([\"Test Test <|loris|>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.460085e-04, 9.997540e-01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "probs = np.array([[9.997540e-01, 2.460085e-04]])\n",
    "np.flip(probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_radford = detector.predict_label(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(y_radford == gold_labels)/ len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.tokenizer.model_max_length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = detector.predict_label(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9978308026030369"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y == gold_labels)/ len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaTokenizerFast(name_or_path='Hello-SimpleAI/chatgpt-detector-roberta', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>', 'additional_special_tokens': ['<|loris|>']}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "\t50265: AddedToken(\"<|loris|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
