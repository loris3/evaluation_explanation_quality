{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "from gpt2outputdataset.detector_radford import DetectorRadford\n",
    "from detectgpt.detector_detectgpt import DetectorDetectGPT\n",
    "from detector_guo import DetectorGuo\n",
    "from detector_dummy import DetectorDummy\n",
    "from explainer_wrappers import LIME_Explainer, SHAP_Explainer, Anchor_Explainer\n",
    "detector_classes = [DetectorDetectGPT]\n",
    "explainer_classes = [  LIME_Explainer]\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle(\"./dataset_test.pkl\")\n",
    "train = pd.read_pickle(\"./dataset_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)+len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3*3*2*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = test[\"answer\"]\n",
    "gold_labels = test[\"author\"] == \"human_answers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for detector_class in detector_classes:\n",
    "#     detector = detector_class()\n",
    "#     start = time.time()\n",
    "#     y = detector.predict_label(documents)\n",
    "#     end = time.time()\n",
    "\n",
    "#     acc = sum(y == gold_labels)/ len(documents)\n",
    "#     results.append((detector.__class__.__name__, acc, end - start))\n",
    "#     print(results[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detector = DetectorDetectGPT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detector.get_pad_token_id_masker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = detector.predict_proba(documents)\n",
    "# yy = np.array(y).argmax(axis=1)\n",
    "# acc = sum(yy == gold_labels)/ len(documents)\n",
    "# acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for document, gt in zip(documents,gold_labels):\n",
    "#     explainer = SHAP_Explainer(detector)\n",
    "#     print(gt)\n",
    "#     display(HTML(explainer.get_vanilla_visualization_HTML(document)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for document in tqdm(documents):\n",
    "#     detector.predict_proba([document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for detector_class in detector_classes:\n",
    "#     detector = detector_class()\n",
    "#     for explainer_class in explainer_classes:\n",
    "#         explainer = explainer_class(detector)\n",
    "#         print(explainer.__class__.__name__, detector.__class__.__name__)\n",
    "#         for document in tqdm(documents):\n",
    "#             explainer.get_explanation_cached(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detector = DetectorDetectGPT()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # detector = DetectorRadford()\n",
    "# explainer = LIME_Explainer(detector)\n",
    "\n",
    "# explainer.get_fi_scores_batch(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = LIME_Explainer(detector)\n",
    "\n",
    "# explainer.get_fi_scores_batch(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector=DetectorDetectGPT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Anchor_Explainer(detector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent = \"This is a sentence, machine human.\"\n",
    "# sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_labels.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words, positions, true_label, sample_fn = explainer.explainer.get_sample_fn(sent, detector.predict_label, onepass=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = sample_fn([], 100)\n",
    "# # [\"\".join(a) for a in sentences.reshape(sentences.shape[0], -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = sample_fn([], 100)\n",
    "# # [\"\".join(a) for a in sentences.reshape(sentences.shape[0], -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5ztrhdgf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'An example is a specific instance or illustration that represents a general idea or concept. It serves to clarify or demonstrate a point, making complex ideas more understandable. For instance, a red apple can be an example of a fruit, showcasing the broader category of fruits through a specific case.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "text = documents.iloc[i]\n",
    "print(gold_labels.iloc[i])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_labels.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\" \".join([t if random.random() < 0.95 else detector.get_pad_token() for t in text.split(\" \")]) for _ in range(0,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.predict_proba([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.predict_label([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT prompt: \"What is an example? Answer in 50 words\"\n",
    "exp = explainer.get_explanation_cached('An example is a specific instance or illustration that represents a general idea or concept. It serves to clarify or demonstrate a point, making complex ideas more understandable. For instance, a red apple can be an example of a fruit, showcasing the broader category of fruits through a specific case.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anchor.anchor import anchor_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_explanation.AnchorExplanation('text', exp, explainer.explainer.as_html).show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[documents.str.split().apply(len)  < 75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(explainer, Anchor_Explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computation_times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document, gt  in tqdm(zip(documents, gold_labels)):\n",
    "\n",
    "    exp = explainer.get_explanation_cached(document)\n",
    "    if isinstance(explainer, Anchor_Explainer):\n",
    "        computation_times.append((exp[\"computation_time\"], gt, detector.predict_label([document])[0], len(document.split(\" \"))))\n",
    "    #anchor_explanation.AnchorExplanation('text', exp, explainer.explainer.as_html).show_in_notebook()\n",
    "    display(pd.DataFrame(computation_times, columns=[\"time\", \"gt\", \"prediction\", \"len\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(computation_times, columns=[\"time\", \"gt\", \"prediction\", \"len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
